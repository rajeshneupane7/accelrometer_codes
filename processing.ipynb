{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e406ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATA PROCESSING PIPELINE\n",
    "# ==========================================\n",
    "class AccelPipeline:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        \n",
    "        # Ensure Timestamp format\n",
    "        self.df['local_ts'] = pd.to_datetime(self.df['local_ts'])\n",
    "        \n",
    "        # Sort by Subject THEN Time to ensure rolling window correctness\n",
    "        self.df = self.df.sort_values(by=['subject', 'local_ts']).reset_index(drop=True)\n",
    "        \n",
    "    def convert_to_gravity(self):\n",
    "        print(\"--- Converting to Gravity Units & Calculating ENMO ---\")\n",
    "        scale = 16384.0\n",
    "        \n",
    "        self.df['x_g'] = self.df['x'] / scale\n",
    "        self.df['y_g'] = self.df['y'] / scale\n",
    "        self.df['z_g'] = self.df['z'] / scale\n",
    "        \n",
    "        # Magnitude\n",
    "        self.df['mag'] = np.sqrt(self.df['x_g']**2 + self.df['y_g']**2 + self.df['z_g']**2)\n",
    "        \n",
    "        # ENMO: max(mag - 1, 0)\n",
    "        self.df['enmo'] = np.maximum(self.df['mag'] - 1, 0)\n",
    "        return self.df\n",
    "\n",
    "    def _get_dynamic_component(self, window_seconds=1):\n",
    "        # Create temp df indexed by time\n",
    "        temp_df = self.df.set_index('local_ts').sort_index()\n",
    "        cols = ['x_g', 'y_g', 'z_g']\n",
    "        \n",
    "        # Group by subject -> Rolling Mean (Static Gravity)\n",
    "        static_component = temp_df.groupby('subject')[cols].rolling(f'{window_seconds}s').mean()\n",
    "        \n",
    "        # Merge static values back to main dataframe\n",
    "        static_reset = static_component.reset_index()\n",
    "        merged = pd.merge(self.df, static_reset, on=['subject', 'local_ts'], suffixes=('', '_static'))\n",
    "        \n",
    "        # Dynamic = Raw - Static\n",
    "        dynamic_df = pd.DataFrame()\n",
    "        dynamic_df['x_d'] = merged['x_g'] - merged['x_g_static']\n",
    "        dynamic_df['y_d'] = merged['y_g'] - merged['y_g_static']\n",
    "        dynamic_df['z_d'] = merged['z_g'] - merged['z_g_static']\n",
    "        \n",
    "        return dynamic_df.fillna(0)\n",
    "\n",
    "    def calc_odba(self):\n",
    "        print(\"--- Calculating ODBA ---\")\n",
    "        dyn = self._get_dynamic_component()\n",
    "        self.df['odba'] = dyn['x_d'].abs() + dyn['y_d'].abs() + dyn['z_d'].abs()\n",
    "        return self.df\n",
    "\n",
    "    def calc_vedba(self):\n",
    "        print(\"--- Calculating VeDBA ---\")\n",
    "        dyn = self._get_dynamic_component()\n",
    "        self.df['vedba'] = np.sqrt(dyn['x_d']**2 + dyn['y_d']**2 + dyn['z_d']**2)\n",
    "        return self.df\n",
    "\n",
    "    def resample_data(self, interval_seconds=5):\n",
    "        print(f\"--- Resampling data to {interval_seconds} second windows ---\")\n",
    "        \n",
    "        # Aggregation Dictionary\n",
    "        agg_dict = {\n",
    "            'x_g': 'mean', 'y_g': 'mean', 'z_g': 'mean',\n",
    "            'mag': 'mean', 'enmo': 'mean',\n",
    "            'odba': 'mean', 'vedba': 'mean',\n",
    "            # UPDATED: Mode for behavioral_category\n",
    "            'behavioral_category': lambda x: x.mode()[0] if not x.mode().empty else np.nan\n",
    "        }\n",
    "        \n",
    "        resampled_df = (\n",
    "            self.df.set_index('local_ts')\n",
    "            .groupby('subject')\n",
    "            .resample(f'{interval_seconds}s')\n",
    "            .agg(agg_dict)\n",
    "        )\n",
    "        \n",
    "        return resampled_df.dropna().reset_index()\n",
    "\n",
    "# ==========================================\n",
    "# 2. MACHINE LEARNING MODELER\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "# 1. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03f45379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb  # Import XGBoost\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Suppress Optuna's massive log output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "class ActivityModeler:\n",
    "    def __init__(self, data, target_col='behavioral_category'):\n",
    "        self.data = data\n",
    "        self.target_col = target_col\n",
    "        self.le = LabelEncoder()\n",
    "        self.results_log = []\n",
    "        \n",
    "        if self.target_col not in self.data.columns:\n",
    "            raise ValueError(f\"Target column '{self.target_col}' not found.\")\n",
    "            \n",
    "        counts = self.data[self.target_col].value_counts().to_dict()\n",
    "        self.target_distribution_str = str(counts)\n",
    "\n",
    "    def prepare_data(self, feature_cols):\n",
    "        X = self.data[feature_cols]\n",
    "        y = self.data[self.target_col]\n",
    "        \n",
    "        # XGBoost requires labels to be integers starting from 0\n",
    "        y_encoded = self.le.fit_transform(y)\n",
    "        \n",
    "        # Stratify to maintain class balance\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    "            )\n",
    "        except ValueError:\n",
    "            # Fallback if a class has too few samples\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.3, random_state=42\n",
    "            )\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def get_optimizer_objective(self, trial, algo_name, X, y):\n",
    "        \"\"\"\n",
    "        Defines the hyperparameter search space for each algorithm.\n",
    "        Returns the cross-validation score to maximize.\n",
    "        \"\"\"\n",
    "        # 1. XGBoost (New)\n",
    "        if algo_name == \"XGBoost\":\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'eval_metric': 'mlogloss',\n",
    "                'random_state': 42\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "\n",
    "        # 2. Random Forest\n",
    "        elif algo_name == \"RandomForest\":\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "                'random_state': 42\n",
    "            }\n",
    "            model = RandomForestClassifier(**params)\n",
    "\n",
    "        # 3. SVM\n",
    "        elif algo_name == \"SVM (RBF)\":\n",
    "            params = {\n",
    "                'C': trial.suggest_float('C', 0.1, 100.0, log=True),\n",
    "                'gamma': trial.suggest_categorical('gamma', ['scale', 'auto']),\n",
    "                'kernel': 'rbf',\n",
    "                'random_state': 42\n",
    "            }\n",
    "            model = SVC(**params)\n",
    "\n",
    "        # 4. KNN\n",
    "        elif algo_name == \"KNN\":\n",
    "            params = {\n",
    "                'n_neighbors': trial.suggest_int('n_neighbors', 3, 20),\n",
    "                'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "                'p': trial.suggest_categorical('p', [1, 2])\n",
    "            }\n",
    "            model = KNeighborsClassifier(**params)\n",
    "\n",
    "        # 5. Logistic Regression\n",
    "        elif algo_name == \"LogisticReg\":\n",
    "            params = {\n",
    "                'C': trial.suggest_float('C', 0.01, 100.0, log=True),\n",
    "                'solver': 'lbfgs',\n",
    "                'max_iter': 2000,\n",
    "                'random_state': 42\n",
    "            }\n",
    "            model = LogisticRegression(**params)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown algorithm: {algo_name}\")\n",
    "\n",
    "        # Cross-Validation\n",
    "        scores = cross_val_score(model, X, y, cv=3, scoring='f1_weighted')\n",
    "        return scores.mean()\n",
    "\n",
    "    def tune_and_evaluate(self, algo_name, X_train, X_test, y_train, y_test, n_trials=10):\n",
    "        \"\"\"\n",
    "        Runs Optuna optimization, then trains the best model.\n",
    "        \"\"\"\n",
    "        # Scaling is crucial for SVM/KNN/LogReg (XGBoost/RF handle unscaled fine, but scaling doesn't hurt)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_s = scaler.fit_transform(X_train)\n",
    "        X_test_s = scaler.transform(X_test)\n",
    "\n",
    "        # --- 1. OPTUNA OPTIMIZATION ---\n",
    "        def objective_wrapper(trial):\n",
    "            return self.get_optimizer_objective(trial, algo_name, X_train_s, y_train)\n",
    "\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective_wrapper, n_trials=n_trials)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "\n",
    "        # --- 2. RE-TRAIN BEST MODEL ---\n",
    "        if algo_name == \"XGBoost\":\n",
    "            # Must ensure fixed params are passed again\n",
    "            model = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "        elif algo_name == \"RandomForest\":\n",
    "            model = RandomForestClassifier(**best_params, random_state=42)\n",
    "        elif algo_name == \"SVM (RBF)\":\n",
    "            model = SVC(**best_params, kernel='rbf', random_state=42)\n",
    "        elif algo_name == \"KNN\":\n",
    "            model = KNeighborsClassifier(**best_params)\n",
    "        elif algo_name == \"LogisticReg\":\n",
    "            model = LogisticRegression(**best_params, solver='lbfgs', max_iter=2000, random_state=42)\n",
    "\n",
    "        model.fit(X_train_s, y_train)\n",
    "        y_pred = model.predict(X_test_s)\n",
    "\n",
    "        # --- 3. CALCULATE METRICS ---\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_test, y_pred, average='weighted', zero_division=0\n",
    "        )\n",
    "\n",
    "        return acc, prec, rec, f1, best_params\n",
    "\n",
    "    def run_optuna_experiments(self, n_trials=10):\n",
    "        \"\"\"\n",
    "        Main loop: Features -> Algorithms -> Optuna Tuning\n",
    "        \"\"\"\n",
    "        base_features = [\n",
    "            (\"Raw Accel\", ['x_g', 'y_g', 'z_g']),\n",
    "            (\"ODBA\", ['odba']),\n",
    "            (\"VeDBA\", ['vedba']),\n",
    "            (\"Magnitude\", ['mag'])\n",
    "        ]\n",
    "        \n",
    "        experiments_to_run = {}\n",
    "        # Individual\n",
    "        for name, cols in base_features:\n",
    "            experiments_to_run[f\"Indiv: {name}\"] = cols\n",
    "            \n",
    "        # Cumulative\n",
    "        curr_cols = []\n",
    "        curr_names = []\n",
    "        for name, cols in base_features:\n",
    "            curr_cols = curr_cols + cols\n",
    "            curr_names.append(name)\n",
    "            seq_name = f\"Seq: {' + '.join(curr_names)}\"\n",
    "            experiments_to_run[seq_name] = curr_cols\n",
    "\n",
    "        # ADDED XGBOOST HERE\n",
    "        algo_names = [\"XGBoost\", \"RandomForest\", \"SVM (RBF)\", \"KNN\", \"LogisticReg\"]\n",
    "        \n",
    "        print(f\"Starting Optuna Tuning on {len(self.data)} rows.\")\n",
    "        print(f\"Optimizing {len(experiments_to_run)} Feature Sets x {len(algo_names)} Models...\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        for feat_name, cols in experiments_to_run.items():\n",
    "            if not set(cols).issubset(self.data.columns):\n",
    "                print(f\"⚠️ Skipping {feat_name} (Missing columns)\")\n",
    "                continue\n",
    "\n",
    "            X_train, X_test, y_train, y_test = self.prepare_data(cols)\n",
    "\n",
    "            for algo in algo_names:\n",
    "                print(f\" Tuning {algo} | Features: {feat_name}...\")\n",
    "                \n",
    "                acc, prec, rec, f1, best_params = self.tune_and_evaluate(\n",
    "                    algo, X_train, X_test, y_train, y_test, n_trials=n_trials\n",
    "                )\n",
    "                \n",
    "                self.results_log.append({\n",
    "                    'Algorithm': algo,\n",
    "                    'Feature_Set': feat_name,\n",
    "                    'Accuracy': round(acc, 4),\n",
    "                    'Precision': round(prec, 4),\n",
    "                    'Recall': round(rec, 4),\n",
    "                    'F1_Score': round(f1, 4),\n",
    "                    'Best_Params': str(best_params),\n",
    "                    'Features_Used': str(cols)\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(self.results_log).sort_values(by='F1_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c417999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "actual_file=[]\n",
    "main_path=\"/home/rajesh/work/acclerometer_project/zip_data\"\n",
    "for zip_file in os.listdir(main_path):\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                zip_path= os.path.join(main_path, zip_file)\n",
    "                with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "                        zf.extractall(temp_dir)\n",
    "                        for root, dirs , files in os.walk(temp_dir):\n",
    "                                for d in dirs:\n",
    "                                        if d.startswith('Processed'):\n",
    "\n",
    "                                                second_path= os.path.join(root, d)\n",
    "                                                for excel_file in os.listdir(second_path):\n",
    "                                                        actual_file.append(pd.read_excel(os.path.join(second_path, excel_file)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07e31985",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.concat(actual_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Converting to Gravity Units & Calculating ENMO ---\n",
      "--- Calculating ODBA ---\n",
      "--- Calculating VeDBA ---\n",
      "--- Resampling data to 5 second windows ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_raw = pd.DataFrame(data)\n",
    "\n",
    "# 2. Run Pipeline\n",
    "pipeline = AccelPipeline(df_raw)\n",
    "pipeline.convert_to_gravity()\n",
    "pipeline.calc_odba()\n",
    "pipeline.calc_vedba()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resampling data to 5 second windows ---\n",
      "Starting Optuna Tuning on 40488 rows.\n",
      "Optimizing 8 Feature Sets x 5 Models...\n",
      "------------------------------------------------------------\n",
      " Tuning XGBoost | Features: Indiv: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:32:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Indiv: Raw Accel...\n",
      " Tuning KNN | Features: Indiv: Raw Accel...\n",
      " Tuning LogisticReg | Features: Indiv: Raw Accel...\n",
      " Tuning XGBoost | Features: Indiv: ODBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:44:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: ODBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: ODBA...\n",
      " Tuning KNN | Features: Indiv: ODBA...\n",
      " Tuning LogisticReg | Features: Indiv: ODBA...\n",
      " Tuning XGBoost | Features: Indiv: VeDBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [10:53:05] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: VeDBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: VeDBA...\n",
      " Tuning KNN | Features: Indiv: VeDBA...\n",
      " Tuning LogisticReg | Features: Indiv: VeDBA...\n",
      " Tuning XGBoost | Features: Indiv: Magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:05:37] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Magnitude...\n",
      " Tuning SVM (RBF) | Features: Indiv: Magnitude...\n",
      " Tuning KNN | Features: Indiv: Magnitude...\n",
      " Tuning LogisticReg | Features: Indiv: Magnitude...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:17:49] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel...\n",
      " Tuning KNN | Features: Seq: Raw Accel...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:29:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA + VeDBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:38:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:49:44] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      "--- Resampling data to 30 second windows ---\n",
      "Starting Optuna Tuning on 6774 rows.\n",
      "Optimizing 8 Feature Sets x 5 Models...\n",
      "------------------------------------------------------------\n",
      " Tuning XGBoost | Features: Indiv: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:58:39] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Indiv: Raw Accel...\n",
      " Tuning KNN | Features: Indiv: Raw Accel...\n",
      " Tuning LogisticReg | Features: Indiv: Raw Accel...\n",
      " Tuning XGBoost | Features: Indiv: ODBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [11:59:29] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: ODBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: ODBA...\n",
      " Tuning KNN | Features: Indiv: ODBA...\n",
      " Tuning LogisticReg | Features: Indiv: ODBA...\n",
      " Tuning XGBoost | Features: Indiv: VeDBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:00:24] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: VeDBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: VeDBA...\n",
      " Tuning KNN | Features: Indiv: VeDBA...\n",
      " Tuning LogisticReg | Features: Indiv: VeDBA...\n",
      " Tuning XGBoost | Features: Indiv: Magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:01:25] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Magnitude...\n",
      " Tuning SVM (RBF) | Features: Indiv: Magnitude...\n",
      " Tuning KNN | Features: Indiv: Magnitude...\n",
      " Tuning LogisticReg | Features: Indiv: Magnitude...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:02:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel...\n",
      " Tuning KNN | Features: Seq: Raw Accel...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:03:00] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA + VeDBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:03:53] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:05:06] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      "--- Resampling data to 45 second windows ---\n",
      "Starting Optuna Tuning on 4528 rows.\n",
      "Optimizing 8 Feature Sets x 5 Models...\n",
      "------------------------------------------------------------\n",
      " Tuning XGBoost | Features: Indiv: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:06:38] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Indiv: Raw Accel...\n",
      " Tuning KNN | Features: Indiv: Raw Accel...\n",
      " Tuning LogisticReg | Features: Indiv: Raw Accel...\n",
      " Tuning XGBoost | Features: Indiv: ODBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:07:28] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: ODBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: ODBA...\n",
      " Tuning KNN | Features: Indiv: ODBA...\n",
      " Tuning LogisticReg | Features: Indiv: ODBA...\n",
      " Tuning XGBoost | Features: Indiv: VeDBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:08:18] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: VeDBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: VeDBA...\n",
      " Tuning KNN | Features: Indiv: VeDBA...\n",
      " Tuning LogisticReg | Features: Indiv: VeDBA...\n",
      " Tuning XGBoost | Features: Indiv: Magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:09:08] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Magnitude...\n",
      " Tuning SVM (RBF) | Features: Indiv: Magnitude...\n",
      " Tuning KNN | Features: Indiv: Magnitude...\n",
      " Tuning LogisticReg | Features: Indiv: Magnitude...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:11:14] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel...\n",
      " Tuning KNN | Features: Seq: Raw Accel...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:12:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA + VeDBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:14:06] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA + VeDBA...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:15:36] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning KNN | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel + ODBA + VeDBA + Magnitude...\n",
      "--- Resampling data to 60 second windows ---\n",
      "Starting Optuna Tuning on 3401 rows.\n",
      "Optimizing 8 Feature Sets x 5 Models...\n",
      "------------------------------------------------------------\n",
      " Tuning XGBoost | Features: Indiv: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:16:51] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Indiv: Raw Accel...\n",
      " Tuning KNN | Features: Indiv: Raw Accel...\n",
      " Tuning LogisticReg | Features: Indiv: Raw Accel...\n",
      " Tuning XGBoost | Features: Indiv: ODBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:17:35] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: ODBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: ODBA...\n",
      " Tuning KNN | Features: Indiv: ODBA...\n",
      " Tuning LogisticReg | Features: Indiv: ODBA...\n",
      " Tuning XGBoost | Features: Indiv: VeDBA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:18:30] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: VeDBA...\n",
      " Tuning SVM (RBF) | Features: Indiv: VeDBA...\n",
      " Tuning KNN | Features: Indiv: VeDBA...\n",
      " Tuning LogisticReg | Features: Indiv: VeDBA...\n",
      " Tuning XGBoost | Features: Indiv: Magnitude...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:20:59] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Indiv: Magnitude...\n",
      " Tuning SVM (RBF) | Features: Indiv: Magnitude...\n",
      " Tuning KNN | Features: Indiv: Magnitude...\n",
      " Tuning LogisticReg | Features: Indiv: Magnitude...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajesh/work/heat_stress_venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [12:31:15] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tuning RandomForest | Features: Seq: Raw Accel...\n",
      " Tuning SVM (RBF) | Features: Seq: Raw Accel...\n",
      " Tuning KNN | Features: Seq: Raw Accel...\n",
      " Tuning LogisticReg | Features: Seq: Raw Accel...\n",
      " Tuning XGBoost | Features: Seq: Raw Accel + ODBA...\n"
     ]
    }
   ],
   "source": [
    "temp_results=[]\n",
    "time_interval=[5,30,45,60,90]\n",
    "for time in time_interval:\n",
    "\n",
    "    df_ready = pipeline.resample_data(interval_seconds=time) \n",
    "\n",
    "    modeler = ActivityModeler(df_ready, target_col='behavioral_category')\n",
    "    df=modeler.run_optuna_experiments()\n",
    "    df['time']= time \n",
    "    temp_results.append(df)\n",
    "final_result= pd.concat(temp_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c48995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/rajesh/work/acclerometer_project/codes/initial_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ae25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heat_stress_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

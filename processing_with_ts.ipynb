{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45f7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Adaptive Filter (Target Cutoff: 5.0Hz) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_486067/4191473207.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  self.df = self.df.groupby('subject', group_keys=False).apply(filter_subject_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Adaptive Filtering Complete ---\n",
      "--- Converting to Gravity & ENMO ---\n",
      "\n",
      "--- Starting Grid Search ---\n",
      "--- Resampling (10s) with Threshold 60.0% ---\n",
      "Generated 19741 labeled windows.\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 5 steps)\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 10 steps)\n",
      "--- Resampling (10s) with Threshold 80.0% ---\n",
      "Generated 18680 labeled windows.\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 5 steps)\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 10 steps)\n",
      "--- Resampling (30s) with Threshold 60.0% ---\n",
      "Generated 6382 labeled windows.\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 5 steps)\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 10 steps)\n",
      "--- Resampling (30s) with Threshold 80.0% ---\n",
      "Generated 5716 labeled windows.\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 5 steps)\n",
      "\n",
      ">>> Running Time Series Model (Lookback: 10 steps)\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "   Accuracy  F1_Score  Time_Steps  Num_Training_Sequences  Window_Size_Sec  \\\n",
      "3  0.929608  0.928017          10                   14888               10   \n",
      "1  0.915121  0.913842          10                   15736               10   \n",
      "7  0.904425  0.900703          10                    4516               30   \n",
      "5  0.877276  0.870692          10                    5049               30   \n",
      "2  0.857603  0.852966           5                   14916               10   \n",
      "6  0.847845  0.842795           5                    4544               30   \n",
      "0  0.831304  0.824163           5                   15764               10   \n",
      "4  0.829134  0.821685           5                    5077               30   \n",
      "\n",
      "   Label_Threshold  \n",
      "3              0.8  \n",
      "1              0.6  \n",
      "7              0.8  \n",
      "5              0.6  \n",
      "2              0.8  \n",
      "6              0.8  \n",
      "0              0.6  \n",
      "4              0.6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from scipy.signal import butter, filtfilt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# ==========================================\n",
    "# 1. ADAPTIVE PIPELINE (Handles Mixed Hz)\n",
    "# ==========================================\n",
    "class AdaptiveAccelPipeline:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df['local_ts'] = pd.to_datetime(self.df['local_ts'])\n",
    "        # Sort is critical for time-series\n",
    "        self.df = self.df.sort_values(by=['subject', 'local_ts']).reset_index(drop=True)\n",
    "\n",
    "    def apply_adaptive_filter(self, target_cutoff_hz=5.0):\n",
    "        \"\"\"\n",
    "        Applies filtering subject-by-subject.\n",
    "        If a subject's sampling rate is too low, it auto-adjusts or skips filtering.\n",
    "        \"\"\"\n",
    "        print(f\"--- Running Adaptive Filter (Target Cutoff: {target_cutoff_hz}Hz) ---\")\n",
    "        \n",
    "        def filter_subject_data(group):\n",
    "            # 1. Calculate Sampling Rate (fs) for THIS subject\n",
    "            # We filter out 0.0 diffs (duplicates) to avoid divide-by-zero\n",
    "            time_diffs = group['local_ts'].diff().dt.total_seconds()\n",
    "            valid_diffs = time_diffs[time_diffs > 0]\n",
    "            \n",
    "            if len(valid_diffs) < 10:\n",
    "                return group # Too little data to process\n",
    "            \n",
    "            median_diff = valid_diffs.median()\n",
    "            if median_diff == 0: return group # Safety catch\n",
    "            \n",
    "            fs = 1 / median_diff\n",
    "            nyquist = 0.5 * fs\n",
    "            \n",
    "            # 2. DECISION LOGIC\n",
    "            # Case A: Data is too slow for the requested filter (e.g., Data is 5Hz, you want 5Hz cut)\n",
    "            if fs <= target_cutoff_hz * 2.0:\n",
    "                # If data is really slow (<10Hz), usually we just skip filtering \n",
    "                # because it's already \"smooth\" compared to 20Hz data.\n",
    "                # Or we apply a very mild smoothing (e.g. 0.8 * Nyquist)\n",
    "                actual_cutoff = nyquist * 0.9 \n",
    "                \n",
    "                # If the resulting cutoff is tiny, just skip it.\n",
    "                if actual_cutoff < 1.0:\n",
    "                    return group \n",
    "            else:\n",
    "                # Case B: Data is fast enough (e.g., 20Hz data, 5Hz cut) -> Use requested cutoff\n",
    "                actual_cutoff = target_cutoff_hz\n",
    "\n",
    "            # 3. Apply Filter\n",
    "            try:\n",
    "                b, a = butter(N=4, Wn=actual_cutoff / nyquist, btype='low')\n",
    "                # Apply to X, Y, Z\n",
    "                for col in ['x', 'y', 'z']:\n",
    "                    group[col] = filtfilt(b, a, group[col])\n",
    "            except Exception as e:\n",
    "                # If math fails (e.g., unstable IIR), return raw data\n",
    "                pass\n",
    "                \n",
    "            return group\n",
    "\n",
    "        # Apply the logic to each subject independently\n",
    "        self.df = self.df.groupby('subject', group_keys=False).apply(filter_subject_data)\n",
    "        print(\"--- Adaptive Filtering Complete ---\")\n",
    "        return self.df\n",
    "\n",
    "    def convert_to_gravity(self):\n",
    "        print(\"--- Converting to Gravity & ENMO ---\")\n",
    "        scale = 16384.0 # Adjust based on your accelerometer range (e.g. +/- 2g vs +/- 4g)\n",
    "        self.df['x_g'] = self.df['x'] / scale\n",
    "        self.df['y_g'] = self.df['y'] / scale\n",
    "        self.df['z_g'] = self.df['z'] / scale\n",
    "        self.df['mag'] = np.sqrt(self.df['x_g']**2 + self.df['y_g']**2 + self.df['z_g']**2)\n",
    "        self.df['enmo'] = np.maximum(self.df['mag'] - 1, 0)\n",
    "        return self.df\n",
    "\n",
    "    def calc_odba(self):\n",
    "        # Simplified ODBA calculation\n",
    "        self.df['odba'] = (self.df['x_g'] - self.df['x_g'].mean()).abs() + \\\n",
    "                          (self.df['y_g'] - self.df['y_g'].mean()).abs() + \\\n",
    "                          (self.df['z_g'] - self.df['z_g'].mean()).abs()\n",
    "        return self.df\n",
    "\n",
    "    def resample_and_label(self, interval_seconds=10, coherence_threshold=0.7):\n",
    "        \"\"\"\n",
    "        Resamples data into windows. \n",
    "        ASSIGN LABELS based on threshold:\n",
    "        If > 70% of the raw samples in the window are 'Grazing', the window is 'Grazing'.\n",
    "        Otherwise, the window is discarded (Ambiguous).\n",
    "        \"\"\"\n",
    "        print(f\"--- Resampling ({interval_seconds}s) with Threshold {coherence_threshold*100}% ---\")\n",
    "        \n",
    "        # Custom Aggregator for Labels\n",
    "        def threshold_labeler(x):\n",
    "            if x.empty: return np.nan\n",
    "            counts = x.value_counts(normalize=True)\n",
    "            # Check if the most frequent label crosses the threshold\n",
    "            if counts.iloc[0] >= coherence_threshold:\n",
    "                return counts.index[0]\n",
    "            return np.nan # Drop this window (too messy/transitioning)\n",
    "\n",
    "        # Feature Aggregators\n",
    "        agg_dict = {\n",
    "            'x_g': ['mean', 'std', 'min', 'max'],\n",
    "            'y_g': ['mean', 'std', 'min', 'max'],\n",
    "            'z_g': ['mean', 'std', 'min', 'max'],\n",
    "            'mag': ['mean', 'std'],      \n",
    "            'enmo': ['mean', 'max'], \n",
    "            'odba': ['mean', 'std'],    \n",
    "            'behavioral_category': threshold_labeler # <--- LOGIC APPLIED HERE\n",
    "        }\n",
    "\n",
    "        resampled = (\n",
    "            self.df.set_index('local_ts')\n",
    "            .groupby('subject')\n",
    "            .resample(f'{interval_seconds}s')\n",
    "            .agg(agg_dict)\n",
    "        )\n",
    "        \n",
    "        # Flatten columns\n",
    "        resampled.columns = [f\"{c[0]}_{c[1]}\" if c[1] else c[0] for c in resampled.columns]\n",
    "        resampled = resampled.rename(columns={'behavioral_category_threshold_labeler': 'label'})\n",
    "        \n",
    "        # DROP windows that failed the threshold check\n",
    "        final_df = resampled.dropna(subset=['label']).reset_index()\n",
    "        \n",
    "        print(f\"Generated {len(final_df)} labeled windows.\")\n",
    "        return final_df\n",
    "\n",
    "    def create_time_series_sequences(self, data, feature_cols, target_col, time_steps=5):\n",
    "        \"\"\"\n",
    "        Converts the resampled windows into sequences for LSTM.\n",
    "        Input: (N, Features) -> Output: (N, TimeSteps, Features)\n",
    "        \"\"\"\n",
    "        X_seq, y_seq = [], []\n",
    "        \n",
    "        # Group by subject to prevent sequences bleeding across different animals\n",
    "        for subject, group in data.groupby('subject'):\n",
    "            group = group.sort_values('local_ts')\n",
    "            feats = group[feature_cols].values\n",
    "            targets = group[target_col].values\n",
    "            \n",
    "            if len(group) < time_steps: continue\n",
    "            \n",
    "            # Sliding window over the WINDOWS\n",
    "            for i in range(len(group) - time_steps):\n",
    "                X_seq.append(feats[i : i + time_steps])\n",
    "                y_seq.append(targets[i + time_steps]) # Predict the label of the *next* window\n",
    "                \n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# ==========================================\n",
    "# 2. DEEP LEARNING ENGINE\n",
    "# ==========================================\n",
    "class TimeSeriesModeler:\n",
    "    def __init__(self, pipeline, df):\n",
    "        self.pipeline = pipeline\n",
    "        self.df = df\n",
    "        self.le = LabelEncoder()\n",
    "        \n",
    "    def run(self, time_steps=5):\n",
    "        print(f\"\\n>>> Running Time Series Model (Lookback: {time_steps} steps)\")\n",
    "        \n",
    "        # 1. Identify Feature Columns (exclude metadata)\n",
    "        feature_cols = [c for c in self.df.columns if c not in ['subject', 'local_ts', 'label']]\n",
    "        \n",
    "        # 2. Encode Labels\n",
    "        self.df['label_encoded'] = self.le.fit_transform(self.df['label'])\n",
    "        num_classes = len(self.le.classes_)\n",
    "        \n",
    "        # 3. Scale Features (Crucial for LSTM)\n",
    "        scaler = StandardScaler()\n",
    "        # We perform scaling on the dataframe before sequencing\n",
    "        scaled_df = self.df.copy()\n",
    "        scaled_df[feature_cols] = scaler.fit_transform(scaled_df[feature_cols])\n",
    "        \n",
    "        # 4. Generate Sequences\n",
    "        X, y = self.pipeline.create_time_series_sequences(\n",
    "            scaled_df, feature_cols, 'label_encoded', time_steps\n",
    "        )\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            print(\"Not enough data for sequences.\")\n",
    "            return None\n",
    "\n",
    "        # 5. One-Hot Encode Targets\n",
    "        y_cat = to_categorical(y, num_classes=num_classes)\n",
    "        \n",
    "        # 6. Train/Test Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # 7. Define LSTM Model\n",
    "        model = Sequential([\n",
    "            Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "            LSTM(64, return_sequences=False),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # 8. Train\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=20, \n",
    "            batch_size=32, \n",
    "            callbacks=[es],\n",
    "            verbose=0 # Silent training\n",
    "        )\n",
    "        \n",
    "        # 9. Evaluate\n",
    "        y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'Accuracy': acc,\n",
    "            'F1_Score': f1,\n",
    "            'Time_Steps': time_steps,\n",
    "            'Num_Training_Sequences': len(X_train)\n",
    "        }\n",
    "\n",
    "# ==========================================\n",
    "# 3. MAIN EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "# A. LOAD DATA\n",
    "actual_file = []\n",
    "main_path = \"/home/rajesh/work/acclerometer_project/zip_data\"\n",
    "\n",
    "if os.path.exists(main_path):\n",
    "    for zip_file in os.listdir(main_path):\n",
    "        if zip_file.endswith(\".zip\"):\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                try:\n",
    "                    with zipfile.ZipFile(os.path.join(main_path, zip_file), \"r\") as zf:\n",
    "                        zf.extractall(temp_dir)\n",
    "                        for root, dirs, files in os.walk(temp_dir):\n",
    "                            for d in dirs:\n",
    "                                if d.startswith('Processed'):\n",
    "                                    sec_path = os.path.join(root, d)\n",
    "                                    for f in os.listdir(sec_path):\n",
    "                                        if f.endswith(('.xls', '.xlsx')):\n",
    "                                            actual_file.append(pd.read_excel(os.path.join(sec_path, f)))\n",
    "                except Exception as e: print(f\"Error: {e}\")\n",
    "    if actual_file: df_raw = pd.concat(actual_file)\n",
    "    else: df_raw = pd.DataFrame() # Handle empty case\n",
    "else:\n",
    "    # Dummy data for testing if path doesn't exist\n",
    "    print(\"Using Dummy Data\")\n",
    "    dates = pd.date_range('2023-01-01', periods=5000, freq='200ms') # 5Hz data\n",
    "    df_raw = pd.DataFrame({\n",
    "        'subject': ['Cow1']*5000,\n",
    "        'local_ts': dates,\n",
    "        'x': np.random.randn(5000)*1000, \n",
    "        'y': np.random.randn(5000)*1000,\n",
    "        'z': np.random.randn(5000)*1000,\n",
    "        'behavioral_category': ['Grazing']*5000\n",
    "    })\n",
    "\n",
    "if not df_raw.empty:\n",
    "    # B. INITIALIZE ADAPTIVE PIPELINE\n",
    "    pipeline = AdaptiveAccelPipeline(df_raw)\n",
    "\n",
    "    # 1. Adaptively Filter (safe for mixed 5Hz/10Hz/20Hz)\n",
    "    pipeline.apply_adaptive_filter(target_cutoff_hz=5.0)\n",
    "\n",
    "    # 2. Physics conversions\n",
    "    pipeline.convert_to_gravity()\n",
    "    pipeline.calc_odba()\n",
    "\n",
    "    results_table = []\n",
    "    \n",
    "    # Grid Search Settings\n",
    "    intervals = [10, 30]  # Window sizes in seconds\n",
    "    thresholds = [0.6, 0.8] # Strictness of labeling (60% vs 80% purity)\n",
    "    lstm_steps = [5, 10]    # How far back the LSTM looks\n",
    "\n",
    "    print(f\"\\n--- Starting Grid Search ---\")\n",
    "    for iv in intervals:\n",
    "        for th in thresholds:\n",
    "            # 3. Resample and Label\n",
    "            # This applies the logic: \"Only keep window if > X% of data matches\"\n",
    "            df_ready = pipeline.resample_and_label(interval_seconds=iv, coherence_threshold=th)\n",
    "            \n",
    "            if len(df_ready) < 100:\n",
    "                print(f\"Skipping Interval={iv}, Threshold={th} (Not enough valid windows)\")\n",
    "                continue\n",
    "\n",
    "            # 4. Run Time Series Model\n",
    "            ts_modeler = TimeSeriesModeler(pipeline, df_ready)\n",
    "            \n",
    "            for steps in lstm_steps:\n",
    "                res = ts_modeler.run(time_steps=steps)\n",
    "                if res:\n",
    "                    res['Window_Size_Sec'] = iv\n",
    "                    res['Label_Threshold'] = th\n",
    "                    results_table.append(res)\n",
    "\n",
    "    # C. SAVE RESULTS\n",
    "    if results_table:\n",
    "        final_df = pd.DataFrame(results_table)\n",
    "        final_df = final_df.sort_values(by='F1_Score', ascending=False)\n",
    "        \n",
    "        print(\"\\n=== FINAL RESULTS ===\")\n",
    "        print(final_df)\n",
    "        \n",
    "        save_path = '/home/rajesh/work/acclerometer_project/codes/timeseries_results.csv'\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        final_df.to_csv(save_path, index=False)\n",
    "    else:\n",
    "        print(\"No results generated.\")\n",
    "else:\n",
    "    print(\"No Data Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ced191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Time_Steps</th>\n",
       "      <th>Num_Training_Sequences</th>\n",
       "      <th>Window_Size_Sec</th>\n",
       "      <th>Label_Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.929608</td>\n",
       "      <td>0.928017</td>\n",
       "      <td>10</td>\n",
       "      <td>14888</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915121</td>\n",
       "      <td>0.913842</td>\n",
       "      <td>10</td>\n",
       "      <td>15736</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.904425</td>\n",
       "      <td>0.900703</td>\n",
       "      <td>10</td>\n",
       "      <td>4516</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.877276</td>\n",
       "      <td>0.870692</td>\n",
       "      <td>10</td>\n",
       "      <td>5049</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.857603</td>\n",
       "      <td>0.852966</td>\n",
       "      <td>5</td>\n",
       "      <td>14916</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.847845</td>\n",
       "      <td>0.842795</td>\n",
       "      <td>5</td>\n",
       "      <td>4544</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831304</td>\n",
       "      <td>0.824163</td>\n",
       "      <td>5</td>\n",
       "      <td>15764</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829134</td>\n",
       "      <td>0.821685</td>\n",
       "      <td>5</td>\n",
       "      <td>5077</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_Score  Time_Steps  Num_Training_Sequences  Window_Size_Sec  \\\n",
       "3  0.929608  0.928017          10                   14888               10   \n",
       "1  0.915121  0.913842          10                   15736               10   \n",
       "7  0.904425  0.900703          10                    4516               30   \n",
       "5  0.877276  0.870692          10                    5049               30   \n",
       "2  0.857603  0.852966           5                   14916               10   \n",
       "6  0.847845  0.842795           5                    4544               30   \n",
       "0  0.831304  0.824163           5                   15764               10   \n",
       "4  0.829134  0.821685           5                    5077               30   \n",
       "\n",
       "   Label_Threshold  \n",
       "3              0.8  \n",
       "1              0.6  \n",
       "7              0.8  \n",
       "5              0.6  \n",
       "2              0.8  \n",
       "6              0.8  \n",
       "0              0.6  \n",
       "4              0.6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf46f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "heat_stress_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

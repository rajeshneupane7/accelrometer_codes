{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45f7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 08:34:17.640866: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-14 08:34:17.668562: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-14 08:34:18.544816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-14 08:34:20.740447: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-14 08:34:20.744489: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 263\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m zipfile.ZipFile(os.path.join(main_path, zip_file), \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m         \u001b[43mzf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m root, dirs, files \u001b[38;5;129;01min\u001b[39;00m os.walk(temp_dir):\n\u001b[32m    265\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dirs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:1757\u001b[39m, in \u001b[36mZipFile.extractall\u001b[39m\u001b[34m(self, path, members, pwd)\u001b[39m\n\u001b[32m   1754\u001b[39m     path = os.fspath(path)\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[32m-> \u001b[39m\u001b[32m1757\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:1815\u001b[39m, in \u001b[36mZipFile._extract_member\u001b[39m\u001b[34m(self, member, targetpath, pwd)\u001b[39m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[32m   1813\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.open(member, pwd=pwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[32m   1814\u001b[39m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[32m-> \u001b[39m\u001b[32m1815\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1817\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/shutil.py:203\u001b[39m, in \u001b[36mcopyfileobj\u001b[39m\u001b[34m(fsrc, fdst, length)\u001b[39m\n\u001b[32m    201\u001b[39m fsrc_read = fsrc.read\n\u001b[32m    202\u001b[39m fdst_write = fdst.write\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m buf := \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    204\u001b[39m     fdst_write(buf)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:1005\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1003\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m   1004\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m-> \u001b[39m\u001b[32m1005\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1006\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m   1007\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/zipfile/__init__.py:1081\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compress_type == ZIP_DEFLATED:\n\u001b[32m   1080\u001b[39m     n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = (\u001b[38;5;28mself\u001b[39m._decompressor.eof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1083\u001b[39m                  \u001b[38;5;28mself\u001b[39m._compress_left <= \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1084\u001b[39m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n\u001b[32m   1085\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from scipy.signal import butter, filtfilt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# ==========================================\n",
    "# 1. ADAPTIVE PIPELINE (Handles Mixed Hz)\n",
    "# ==========================================\n",
    "class AdaptiveAccelPipeline:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df['local_ts'] = pd.to_datetime(self.df['local_ts'])\n",
    "        # Sort is critical for time-series\n",
    "        self.df = self.df.sort_values(by=['subject', 'local_ts']).reset_index(drop=True)\n",
    "\n",
    "    def apply_adaptive_filter(self, target_cutoff_hz=5.0):\n",
    "        \"\"\"\n",
    "        Applies filtering subject-by-subject.\n",
    "        If a subject's sampling rate is too low, it auto-adjusts or skips filtering.\n",
    "        \"\"\"\n",
    "        print(f\"--- Running Adaptive Filter (Target Cutoff: {target_cutoff_hz}Hz) ---\")\n",
    "        \n",
    "        def filter_subject_data(group):\n",
    "            # 1. Calculate Sampling Rate (fs) for THIS subject\n",
    "            # We filter out 0.0 diffs (duplicates) to avoid divide-by-zero\n",
    "            time_diffs = group['local_ts'].diff().dt.total_seconds()\n",
    "            valid_diffs = time_diffs[time_diffs > 0]\n",
    "            \n",
    "            if len(valid_diffs) < 10:\n",
    "                return group # Too little data to process\n",
    "            \n",
    "            median_diff = valid_diffs.median()\n",
    "            if median_diff == 0: return group # Safety catch\n",
    "            \n",
    "            fs = 1 / median_diff\n",
    "            nyquist = 0.5 * fs\n",
    "            \n",
    "            # 2. DECISION LOGIC\n",
    "            # Case A: Data is too slow for the requested filter (e.g., Data is 5Hz, you want 5Hz cut)\n",
    "            if fs <= target_cutoff_hz * 2.0:\n",
    "                # If data is really slow (<10Hz), usually we just skip filtering \n",
    "                # because it's already \"smooth\" compared to 20Hz data.\n",
    "                # Or we apply a very mild smoothing (e.g. 0.8 * Nyquist)\n",
    "                actual_cutoff = nyquist * 0.9 \n",
    "                \n",
    "                # If the resulting cutoff is tiny, just skip it.\n",
    "                if actual_cutoff < 1.0:\n",
    "                    return group \n",
    "            else:\n",
    "                # Case B: Data is fast enough (e.g., 20Hz data, 5Hz cut) -> Use requested cutoff\n",
    "                actual_cutoff = target_cutoff_hz\n",
    "\n",
    "            # 3. Apply Filter\n",
    "            try:\n",
    "                b, a = butter(N=4, Wn=actual_cutoff / nyquist, btype='low')\n",
    "                # Apply to X, Y, Z\n",
    "                for col in ['x', 'y', 'z']:\n",
    "                    group[col] = filtfilt(b, a, group[col])\n",
    "            except Exception as e:\n",
    "                # If math fails (e.g., unstable IIR), return raw data\n",
    "                pass\n",
    "                \n",
    "            return group\n",
    "\n",
    "        # Apply the logic to each subject independently\n",
    "        self.df = self.df.groupby('subject', group_keys=False).apply(filter_subject_data)\n",
    "        print(\"--- Adaptive Filtering Complete ---\")\n",
    "        return self.df\n",
    "\n",
    "    def convert_to_gravity(self):\n",
    "        print(\"--- Converting to Gravity & ENMO ---\")\n",
    "        scale = 16384.0 # Adjust based on your accelerometer range (e.g. +/- 2g vs +/- 4g)\n",
    "        self.df['x_g'] = self.df['x'] / scale\n",
    "        self.df['y_g'] = self.df['y'] / scale\n",
    "        self.df['z_g'] = self.df['z'] / scale\n",
    "        self.df['mag'] = np.sqrt(self.df['x_g']**2 + self.df['y_g']**2 + self.df['z_g']**2)\n",
    "        self.df['enmo'] = np.maximum(self.df['mag'] - 1, 0)\n",
    "        return self.df\n",
    "\n",
    "    def calc_odba(self):\n",
    "        # Simplified ODBA calculation\n",
    "        self.df['odba'] = (self.df['x_g'] - self.df['x_g'].mean()).abs() + \\\n",
    "                          (self.df['y_g'] - self.df['y_g'].mean()).abs() + \\\n",
    "                          (self.df['z_g'] - self.df['z_g'].mean()).abs()\n",
    "        return self.df\n",
    "\n",
    "    def resample_and_label(self, interval_seconds=10, coherence_threshold=0.7):\n",
    "        \"\"\"\n",
    "        Resamples data into windows. \n",
    "        ASSIGN LABELS based on threshold:\n",
    "        If > 70% of the raw samples in the window are 'Grazing', the window is 'Grazing'.\n",
    "        Otherwise, the window is discarded (Ambiguous).\n",
    "        \"\"\"\n",
    "        print(f\"--- Resampling ({interval_seconds}s) with Threshold {coherence_threshold*100}% ---\")\n",
    "        \n",
    "        # Custom Aggregator for Labels\n",
    "        def threshold_labeler(x):\n",
    "            if x.empty: return np.nan\n",
    "            counts = x.value_counts(normalize=True)\n",
    "            # Check if the most frequent label crosses the threshold\n",
    "            if counts.iloc[0] >= coherence_threshold:\n",
    "                return counts.index[0]\n",
    "            return np.nan # Drop this window (too messy/transitioning)\n",
    "\n",
    "        # Feature Aggregators\n",
    "        agg_dict = {\n",
    "            'x_g': ['mean', 'std', 'min', 'max'],\n",
    "            'y_g': ['mean', 'std', 'min', 'max'],\n",
    "            'z_g': ['mean', 'std', 'min', 'max'],\n",
    "            'mag': ['mean', 'std'],      \n",
    "            'enmo': ['mean', 'max'], \n",
    "            'odba': ['mean', 'std'],    \n",
    "            'behavioral_category': threshold_labeler # <--- LOGIC APPLIED HERE\n",
    "        }\n",
    "\n",
    "        resampled = (\n",
    "            self.df.set_index('local_ts')\n",
    "            .groupby('subject')\n",
    "            .resample(f'{interval_seconds}s')\n",
    "            .agg(agg_dict)\n",
    "        )\n",
    "        \n",
    "        # Flatten columns\n",
    "        resampled.columns = [f\"{c[0]}_{c[1]}\" if c[1] else c[0] for c in resampled.columns]\n",
    "        resampled = resampled.rename(columns={'behavioral_category_threshold_labeler': 'label'})\n",
    "        \n",
    "        # DROP windows that failed the threshold check\n",
    "        final_df = resampled.dropna(subset=['label']).reset_index()\n",
    "        \n",
    "        print(f\"Generated {len(final_df)} labeled windows.\")\n",
    "        return final_df\n",
    "\n",
    "    def create_time_series_sequences(self, data, feature_cols, target_col, time_steps=5):\n",
    "        \"\"\"\n",
    "        Converts the resampled windows into sequences for LSTM.\n",
    "        Input: (N, Features) -> Output: (N, TimeSteps, Features)\n",
    "        \"\"\"\n",
    "        X_seq, y_seq = [], []\n",
    "        \n",
    "        # Group by subject to prevent sequences bleeding across different animals\n",
    "        for subject, group in data.groupby('subject'):\n",
    "            group = group.sort_values('local_ts')\n",
    "            feats = group[feature_cols].values\n",
    "            targets = group[target_col].values\n",
    "            \n",
    "            if len(group) < time_steps: continue\n",
    "            \n",
    "            # Sliding window over the WINDOWS\n",
    "            for i in range(len(group) - time_steps):\n",
    "                X_seq.append(feats[i : i + time_steps])\n",
    "                y_seq.append(targets[i + time_steps]) # Predict the label of the *next* window\n",
    "                \n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# ==========================================\n",
    "# 2. DEEP LEARNING ENGINE\n",
    "# ==========================================\n",
    "class TimeSeriesModeler:\n",
    "    def __init__(self, pipeline, df):\n",
    "        self.pipeline = pipeline\n",
    "        self.df = df\n",
    "        self.le = LabelEncoder()\n",
    "        \n",
    "    def run(self, time_steps=5):\n",
    "        print(f\"\\n>>> Running Time Series Model (Lookback: {time_steps} steps)\")\n",
    "        \n",
    "        # 1. Identify Feature Columns (exclude metadata)\n",
    "        feature_cols = [c for c in self.df.columns if c not in ['subject', 'local_ts', 'label']]\n",
    "        \n",
    "        # 2. Encode Labels\n",
    "        self.df['label_encoded'] = self.le.fit_transform(self.df['label'])\n",
    "        num_classes = len(self.le.classes_)\n",
    "        \n",
    "        # 3. Scale Features (Crucial for LSTM)\n",
    "        scaler = StandardScaler()\n",
    "        # We perform scaling on the dataframe before sequencing\n",
    "        scaled_df = self.df.copy()\n",
    "        scaled_df[feature_cols] = scaler.fit_transform(scaled_df[feature_cols])\n",
    "        \n",
    "        # 4. Generate Sequences\n",
    "        X, y = self.pipeline.create_time_series_sequences(\n",
    "            scaled_df, feature_cols, 'label_encoded', time_steps\n",
    "        )\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            print(\"Not enough data for sequences.\")\n",
    "            return None\n",
    "\n",
    "        # 5. One-Hot Encode Targets\n",
    "        y_cat = to_categorical(y, num_classes=num_classes)\n",
    "        \n",
    "        # 6. Train/Test Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # 7. Define LSTM Model\n",
    "        model = Sequential([\n",
    "            Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "            LSTM(64, return_sequences=False),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # 8. Train\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        history = model.fit(\n",
    "            X_train, y_train, \n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=20, \n",
    "            batch_size=32, \n",
    "            callbacks=[es],\n",
    "            verbose=0 # Silent training\n",
    "        )\n",
    "        \n",
    "        # 9. Evaluate\n",
    "        y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "        y_true = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'Accuracy': acc,\n",
    "            'F1_Score': f1,\n",
    "            'Time_Steps': time_steps,\n",
    "            'Num_Training_Sequences': len(X_train)\n",
    "            \n",
    "        }\n",
    "\n",
    "# ==========================================\n",
    "# 3. MAIN EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "# A. LOAD DATA\n",
    "actual_file = []\n",
    "main_path = \"/home/rajesh/work/acclerometer_project/zip_data\"\n",
    "\n",
    "if os.path.exists(main_path):\n",
    "    for zip_file in os.listdir(main_path):\n",
    "        if zip_file.endswith(\".zip\"):\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                try:\n",
    "                    with zipfile.ZipFile(os.path.join(main_path, zip_file), \"r\") as zf:\n",
    "                        zf.extractall(temp_dir)\n",
    "                        for root, dirs, files in os.walk(temp_dir):\n",
    "                            for d in dirs:\n",
    "                                if d.startswith('Processed'):\n",
    "                                    sec_path = os.path.join(root, d)\n",
    "                                    for f in os.listdir(sec_path):\n",
    "                                        if f.endswith(('.xls', '.xlsx')):\n",
    "                                            actual_file.append(pd.read_excel(os.path.join(sec_path, f)))\n",
    "                except Exception as e: print(f\"Error: {e}\")\n",
    "    if actual_file: df_raw = pd.concat(actual_file)\n",
    "    else: df_raw = pd.DataFrame() # Handle empty case\n",
    "else:\n",
    "    # Dummy data for testing if path doesn't exist\n",
    "    print(\"Using Dummy Data\")\n",
    "    dates = pd.date_range('2023-01-01', periods=5000, freq='200ms') # 5Hz data\n",
    "    df_raw = pd.DataFrame({\n",
    "        'subject': ['Cow1']*5000,\n",
    "        'local_ts': dates,\n",
    "        'x': np.random.randn(5000)*1000, \n",
    "        'y': np.random.randn(5000)*1000,\n",
    "        'z': np.random.randn(5000)*1000,\n",
    "        'behavioral_category': ['Grazing']*5000\n",
    "    })\n",
    "\n",
    "if not df_raw.empty:\n",
    "    # B. INITIALIZE ADAPTIVE PIPELINE\n",
    "    pipeline = AdaptiveAccelPipeline(df_raw)\n",
    "\n",
    "    # 1. Adaptively Filter (safe for mixed 5Hz/10Hz/20Hz)\n",
    "    pipeline.apply_adaptive_filter(target_cutoff_hz=5.0)\n",
    "\n",
    "    # 2. Physics conversions\n",
    "    pipeline.convert_to_gravity()\n",
    "    pipeline.calc_odba()\n",
    "\n",
    "    results_table = []\n",
    "    \n",
    "    # Grid Search Settings\n",
    "    intervals = [10, 30]  # Window sizes in seconds\n",
    "    thresholds = [0.6, 0.8] # Strictness of labeling (60% vs 80% purity)\n",
    "    lstm_steps = [5, 10]    # How far back the LSTM looks\n",
    "\n",
    "    print(f\"\\n--- Starting Grid Search ---\")\n",
    "    for iv in intervals:\n",
    "        for th in thresholds:\n",
    "            # 3. Resample and Label\n",
    "            # This applies the logic: \"Only keep window if > X% of data matches\"\n",
    "            df_ready = pipeline.resample_and_label(interval_seconds=iv, coherence_threshold=th)\n",
    "            \n",
    "            if len(df_ready) < 100:\n",
    "                print(f\"Skipping Interval={iv}, Threshold={th} (Not enough valid windows)\")\n",
    "                continue\n",
    "\n",
    "            # 4. Run Time Series Model\n",
    "            ts_modeler = TimeSeriesModeler(pipeline, df_ready)\n",
    "            \n",
    "            for steps in lstm_steps:\n",
    "                res = ts_modeler.run(time_steps=steps)\n",
    "                if res:\n",
    "                    res['Window_Size_Sec'] = iv\n",
    "                    res['Label_Threshold'] = th\n",
    "                    results_table.append(res)\n",
    "\n",
    "    # C. SAVE RESULTS\n",
    "    if results_table:\n",
    "        final_df = pd.DataFrame(results_table)\n",
    "        final_df = final_df.sort_values(by='F1_Score', ascending=False)\n",
    "        \n",
    "        print(\"\\n=== FINAL RESULTS ===\")\n",
    "        print(final_df)\n",
    "        \n",
    "        save_path = '/home/rajesh/work/acclerometer_project/codes/timeseries_results.csv'\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        final_df.to_csv(save_path, index=False)\n",
    "    else:\n",
    "        print(\"No results generated.\")\n",
    "else:\n",
    "    print(\"No Data Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ced191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Time_Steps</th>\n",
       "      <th>Num_Training_Sequences</th>\n",
       "      <th>Window_Size_Sec</th>\n",
       "      <th>Label_Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.929608</td>\n",
       "      <td>0.928017</td>\n",
       "      <td>10</td>\n",
       "      <td>14888</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.915121</td>\n",
       "      <td>0.913842</td>\n",
       "      <td>10</td>\n",
       "      <td>15736</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.904425</td>\n",
       "      <td>0.900703</td>\n",
       "      <td>10</td>\n",
       "      <td>4516</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.877276</td>\n",
       "      <td>0.870692</td>\n",
       "      <td>10</td>\n",
       "      <td>5049</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.857603</td>\n",
       "      <td>0.852966</td>\n",
       "      <td>5</td>\n",
       "      <td>14916</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.847845</td>\n",
       "      <td>0.842795</td>\n",
       "      <td>5</td>\n",
       "      <td>4544</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831304</td>\n",
       "      <td>0.824163</td>\n",
       "      <td>5</td>\n",
       "      <td>15764</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.829134</td>\n",
       "      <td>0.821685</td>\n",
       "      <td>5</td>\n",
       "      <td>5077</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_Score  Time_Steps  Num_Training_Sequences  Window_Size_Sec  \\\n",
       "3  0.929608  0.928017          10                   14888               10   \n",
       "1  0.915121  0.913842          10                   15736               10   \n",
       "7  0.904425  0.900703          10                    4516               30   \n",
       "5  0.877276  0.870692          10                    5049               30   \n",
       "2  0.857603  0.852966           5                   14916               10   \n",
       "6  0.847845  0.842795           5                    4544               30   \n",
       "0  0.831304  0.824163           5                   15764               10   \n",
       "4  0.829134  0.821685           5                    5077               30   \n",
       "\n",
       "   Label_Threshold  \n",
       "3              0.8  \n",
       "1              0.6  \n",
       "7              0.8  \n",
       "5              0.6  \n",
       "2              0.8  \n",
       "6              0.8  \n",
       "0              0.6  \n",
       "4              0.6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbf46f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "import copy\n",
    "\n",
    "# Suppress warnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. ADAPTIVE PIPELINE (Data Processing)\n",
    "# ==========================================\n",
    "class AdaptiveAccelPipeline:\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df['local_ts'] = pd.to_datetime(self.df['local_ts'])\n",
    "        self.df = self.df.sort_values(by=['subject', 'local_ts']).reset_index(drop=True)\n",
    "\n",
    "    def apply_adaptive_filter(self, target_cutoff_hz=5.0):\n",
    "        print(f\"--- Running Adaptive Filter (Target Cutoff: {target_cutoff_hz}Hz) ---\")\n",
    "        \n",
    "        def filter_subject_data(group):\n",
    "            time_diffs = group['local_ts'].diff().dt.total_seconds()\n",
    "            valid_diffs = time_diffs[time_diffs > 0]\n",
    "            \n",
    "            if len(valid_diffs) < 10: return group\n",
    "            \n",
    "            median_diff = valid_diffs.median()\n",
    "            if median_diff == 0: return group\n",
    "            \n",
    "            fs = 1 / median_diff\n",
    "            nyquist = 0.5 * fs\n",
    "            \n",
    "            if fs <= target_cutoff_hz * 2.0:\n",
    "                actual_cutoff = nyquist * 0.9 \n",
    "                if actual_cutoff < 1.0: return group \n",
    "            else:\n",
    "                actual_cutoff = target_cutoff_hz\n",
    "\n",
    "            try:\n",
    "                b, a = butter(N=4, Wn=actual_cutoff / nyquist, btype='low')\n",
    "                for col in ['x', 'y', 'z']:\n",
    "                    group[col] = filtfilt(b, a, group[col])\n",
    "            except Exception:\n",
    "                pass\n",
    "            return group\n",
    "\n",
    "        self.df = self.df.groupby('subject', group_keys=False).apply(filter_subject_data)\n",
    "        print(\"--- Adaptive Filtering Complete ---\")\n",
    "        return self.df\n",
    "\n",
    "    def convert_to_gravity(self):\n",
    "        scale = 16384.0 \n",
    "        self.df['x_g'] = self.df['x'] / scale\n",
    "        self.df['y_g'] = self.df['y'] / scale\n",
    "        self.df['z_g'] = self.df['z'] / scale\n",
    "        self.df['mag'] = np.sqrt(self.df['x_g']**2 + self.df['y_g']**2 + self.df['z_g']**2)\n",
    "        self.df['enmo'] = np.maximum(self.df['mag'] - 1, 0)\n",
    "        return self.df\n",
    "\n",
    "    def calc_odba(self):\n",
    "        self.df['odba'] = (self.df['x_g'] - self.df['x_g'].mean()).abs() + \\\n",
    "                          (self.df['y_g'] - self.df['y_g'].mean()).abs() + \\\n",
    "                          (self.df['z_g'] - self.df['z_g'].mean()).abs()\n",
    "        return self.df\n",
    "\n",
    "    def resample_and_label(self, interval_seconds=10, coherence_threshold=0.7):\n",
    "        print(f\"--- Resampling ({interval_seconds}s) with Threshold {coherence_threshold*100}% ---\")\n",
    "        \n",
    "        def threshold_labeler(x):\n",
    "            if x.empty: return np.nan\n",
    "            counts = x.value_counts(normalize=True)\n",
    "            if counts.iloc[0] >= coherence_threshold:\n",
    "                return counts.index[0]\n",
    "            return np.nan \n",
    "\n",
    "        agg_dict = {\n",
    "            'x_g': ['mean', 'std', 'min', 'max'],\n",
    "            'y_g': ['mean', 'std', 'min', 'max'],\n",
    "            'z_g': ['mean', 'std', 'min', 'max'],\n",
    "            'mag': ['mean', 'std'],      \n",
    "            'enmo': ['mean', 'max'], \n",
    "            'odba': ['mean', 'std'],    \n",
    "            'behavioral_category': threshold_labeler \n",
    "        }\n",
    "\n",
    "        resampled = (\n",
    "            self.df.set_index('local_ts')\n",
    "            .groupby('subject')\n",
    "            .resample(f'{interval_seconds}s')\n",
    "            .agg(agg_dict)\n",
    "        )\n",
    "        \n",
    "        resampled.columns = [f\"{c[0]}_{c[1]}\" if c[1] else c[0] for c in resampled.columns]\n",
    "        resampled = resampled.rename(columns={'behavioral_category_threshold_labeler': 'label'})\n",
    "        final_df = resampled.dropna(subset=['label']).reset_index()\n",
    "        \n",
    "        print(f\"Generated {len(final_df)} labeled windows.\")\n",
    "        return final_df\n",
    "\n",
    "    def create_time_series_sequences(self, data, feature_cols, target_col, time_steps=5):\n",
    "        X_seq, y_seq = [], []\n",
    "        \n",
    "        for subject, group in data.groupby('subject'):\n",
    "            group = group.sort_values('local_ts')\n",
    "            feats = group[feature_cols].values\n",
    "            targets = group[target_col].values\n",
    "            \n",
    "            if len(group) < time_steps: continue\n",
    "            \n",
    "            for i in range(len(group) - time_steps):\n",
    "                X_seq.append(feats[i : i + time_steps])\n",
    "                y_seq.append(targets[i + time_steps]) \n",
    "                \n",
    "        return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# ==========================================\n",
    "# 2. PYTORCH MODEL DEFINITION\n",
    "# ==========================================\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, dropout=0.3):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, output_dim)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -1, :] \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# ==========================================\n",
    "# 3. PYTORCH ENGINE\n",
    "# ==========================================\n",
    "class PytorchTimeSeriesModeler:\n",
    "    def __init__(self, pipeline, df):\n",
    "        self.pipeline = pipeline\n",
    "        self.df = df\n",
    "        self.le = LabelEncoder()\n",
    "        \n",
    "    def run(self, time_steps=5, epochs=150, batch_size=32, patience=5):\n",
    "        print(f\"\\n>>> Running PyTorch Time Series Model (Lookback: {time_steps} steps)\")\n",
    "        \n",
    "        # 1. Prepare Data\n",
    "        # FIX: Added 'label_encoded' to the exclusion list to prevent it from being treated as a feature in 2nd loop iteration\n",
    "        feature_cols = [c for c in self.df.columns if c not in ['subject', 'local_ts', 'label', 'label_encoded']]\n",
    "        \n",
    "        self.df['label_encoded'] = self.le.fit_transform(self.df['label'])\n",
    "        num_classes = len(self.le.classes_)\n",
    "        \n",
    "        # Scale Features\n",
    "        scaler = StandardScaler()\n",
    "        scaled_df = self.df.copy()\n",
    "        \n",
    "        # Only scale the feature columns, keeping label_encoded untouched\n",
    "        scaled_df[feature_cols] = scaler.fit_transform(scaled_df[feature_cols])\n",
    "        \n",
    "        # Generate Sequences\n",
    "        X, y = self.pipeline.create_time_series_sequences(\n",
    "            scaled_df, feature_cols, 'label_encoded', time_steps\n",
    "        )\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            print(\"Not enough data for sequences.\")\n",
    "            return None\n",
    "\n",
    "        # Split with Stratification\n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "        except ValueError:\n",
    "            print(\"Warning: Stratification failed (class imbalance?), falling back to random split.\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42\n",
    "            )\n",
    "\n",
    "        # -----------------------------------------------------------\n",
    "        # Calculate and Format Test Label Counts\n",
    "        # -----------------------------------------------------------\n",
    "        unique_labels, counts = np.unique(y_test, return_counts=True)\n",
    "        # Convert integer labels back to strings\n",
    "        label_names = self.le.inverse_transform(unique_labels)\n",
    "        test_counts_dict = dict(zip(label_names, counts))\n",
    "        test_counts_str = str(test_counts_dict)\n",
    "        \n",
    "        print(f\"[INFO] Test Set Distribution: {test_counts_str}\")\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        # Convert to PyTorch Tensors\n",
    "        train_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).long())\n",
    "        test_dataset = TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).long())\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        # 2. Initialize Model\n",
    "        input_dim = X_train.shape[2]\n",
    "        model = LSTMClassifier(input_dim=input_dim, hidden_dim=64, output_dim=num_classes)\n",
    "        model.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        # 3. Training Loop\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            \n",
    "            for X_batch, y_batch in train_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "            \n",
    "            # Validation Phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for X_batch, y_batch in test_loader:\n",
    "                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                    outputs = model(X_batch)\n",
    "                    loss = criterion(outputs, y_batch)\n",
    "                    val_loss += loss.item() * X_batch.size(0)\n",
    "            \n",
    "            val_loss = val_loss / len(test_loader.dataset)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "        \n",
    "        model.load_state_dict(best_model_wts)\n",
    "        \n",
    "        # 4. Final Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(y_batch.numpy())\n",
    "                \n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'Accuracy': acc,\n",
    "            'F1_Score': f1,\n",
    "            'Time_Steps': time_steps,\n",
    "            'Num_Training_Sequences': len(X_train),\n",
    "            'Test_Samples': len(y_test),\n",
    "            'Test_Label_Counts': test_counts_str\n",
    "        }\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "# A. LOAD DATA\n",
    "# actual_file = []\n",
    "# main_path = \"/home/rajesh/work/acclerometer_project/zip_data\"\n",
    "\n",
    "# if os.path.exists(main_path):\n",
    "#     for zip_file in os.listdir(main_path):\n",
    "#         if zip_file.endswith(\".zip\"):\n",
    "#             with tempfile.TemporaryDirectory() as temp_dir:\n",
    "#                 try:\n",
    "#                     with zipfile.ZipFile(os.path.join(main_path, zip_file), \"r\") as zf:\n",
    "#                         zf.extractall(temp_dir)\n",
    "#                         for root, dirs, files in os.walk(temp_dir):\n",
    "#                             for d in dirs:\n",
    "#                                 if d.startswith('Processed'):\n",
    "#                                     sec_path = os.path.join(root, d)\n",
    "#                                     for f in os.listdir(sec_path):\n",
    "#                                         if f.endswith(('.xls', '.xlsx')):\n",
    "#                                             actual_file.append(pd.read_excel(os.path.join(sec_path, f)))\n",
    "#                 except Exception as e: print(f\"Error: {e}\")\n",
    "#     if actual_file: df_raw = pd.concat(actual_file)\n",
    "#     else: df_raw = pd.DataFrame() \n",
    "# else:\n",
    "#     # Dummy data\n",
    "#     print(\"Using Dummy Data\")\n",
    "#     dates = pd.date_range('2023-01-01', periods=5000, freq='200ms')\n",
    "#     df_raw = pd.DataFrame({\n",
    "#         'subject': ['Cow1']*5000,\n",
    "#         'local_ts': dates,\n",
    "#         'x': np.random.randn(5000)*1000, \n",
    "#         'y': np.random.randn(5000)*1000,\n",
    "#         'z': np.random.randn(5000)*1000,\n",
    "#         'behavioral_category': ['Grazing']*2500 + ['Ruminating']*2500\n",
    "#     })\n",
    "\n",
    "# if not df_raw.empty:\n",
    "#     # B. INITIALIZE PIPELINE\n",
    "#     pipeline = AdaptiveAccelPipeline(df_raw)\n",
    "#     pipeline.apply_adaptive_filter(target_cutoff_hz=5.0)\n",
    "#     pipeline.convert_to_gravity()\n",
    "#     pipeline.calc_odba()\n",
    "\n",
    "#     results_table = []\n",
    "    \n",
    "#     # Grid Search\n",
    "#     intervals = [5,10,15, 30] \n",
    "#     thresholds = [0.6,0.7, 0.8] \n",
    "#     lstm_steps = [5, 10,15]    \n",
    "\n",
    "#     print(f\"\\n--- Starting Grid Search (PyTorch) ---\")\n",
    "#     for iv in intervals:\n",
    "#         for th in thresholds:\n",
    "#             df_ready = pipeline.resample_and_label(interval_seconds=iv, coherence_threshold=th)\n",
    "            \n",
    "#             if len(df_ready) < 100:\n",
    "#                 print(f\"Skipping Interval={iv}, Threshold={th} (Not enough valid windows)\")\n",
    "#                 continue\n",
    "\n",
    "#             # 4. Run PyTorch Time Series Model\n",
    "#             ts_modeler = PytorchTimeSeriesModeler(pipeline, df_ready)\n",
    "            \n",
    "#             for steps in lstm_steps:\n",
    "#                 res = ts_modeler.run(time_steps=steps, epochs=20, batch_size=32)\n",
    "#                 if res:\n",
    "#                     res['Window_Size_Sec'] = iv\n",
    "#                     res['Label_Threshold'] = th\n",
    "#                     results_table.append(res)\n",
    "\n",
    "#     # C. SAVE RESULTS\n",
    "#     if results_table:\n",
    "#         final_df = pd.DataFrame(results_table)\n",
    "#         final_df = final_df.sort_values(by='F1_Score', ascending=False)\n",
    "        \n",
    "#         print(\"\\n=== FINAL RESULTS ===\")\n",
    "#         print(final_df)\n",
    "        \n",
    "#         save_path = '/home/rajesh/work/acclerometer_project/codes/pytorch_results.csv'\n",
    "#         os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "#         final_df.to_csv(save_path, index=False)\n",
    "#     else:\n",
    "#         print(\"No results generated.\")\n",
    "# else:\n",
    "#     print(\"No Data Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a19d31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Grid Search (PyTorch) ---\n",
      "--- Resampling (5s) with Threshold 60.0% ---\n",
      "Generated 40056 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2628), 'Resting': np.int64(3041), 'Resting Ruminating': np.int64(1579), 'Walking': np.int64(757)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2627), 'Resting': np.int64(3036), 'Resting Ruminating': np.int64(1579), 'Walking': np.int64(756)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2626), 'Resting': np.int64(3032), 'Resting Ruminating': np.int64(1579), 'Walking': np.int64(754)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2624), 'Resting': np.int64(3027), 'Resting Ruminating': np.int64(1579), 'Walking': np.int64(754)}\n",
      "--- Resampling (5s) with Threshold 70.0% ---\n",
      "Generated 39272 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2593), 'Resting': np.int64(2992), 'Resting Ruminating': np.int64(1574), 'Walking': np.int64(689)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2592), 'Resting': np.int64(2987), 'Resting Ruminating': np.int64(1575), 'Walking': np.int64(687)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2590), 'Resting': np.int64(2983), 'Resting Ruminating': np.int64(1575), 'Walking': np.int64(686)}\n",
      "Early stopping at epoch 20\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2589), 'Resting': np.int64(2978), 'Resting Ruminating': np.int64(1574), 'Walking': np.int64(686)}\n",
      "--- Resampling (5s) with Threshold 80.0% ---\n",
      "Generated 38799 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2566), 'Resting': np.int64(2963), 'Resting Ruminating': np.int64(1570), 'Walking': np.int64(654)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2565), 'Resting': np.int64(2958), 'Resting Ruminating': np.int64(1570), 'Walking': np.int64(653)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2563), 'Resting': np.int64(2953), 'Resting Ruminating': np.int64(1571), 'Walking': np.int64(652)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(2562), 'Resting': np.int64(2948), 'Resting Ruminating': np.int64(1570), 'Walking': np.int64(652)}\n",
      "--- Resampling (10s) with Threshold 60.0% ---\n",
      "Generated 19741 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1301), 'Resting': np.int64(1507), 'Resting Ruminating': np.int64(789), 'Walking': np.int64(345)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1299), 'Resting': np.int64(1502), 'Resting Ruminating': np.int64(789), 'Walking': np.int64(345)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1298), 'Resting': np.int64(1496), 'Resting Ruminating': np.int64(789), 'Walking': np.int64(345)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1298), 'Resting': np.int64(1489), 'Resting Ruminating': np.int64(789), 'Walking': np.int64(345)}\n",
      "--- Resampling (10s) with Threshold 70.0% ---\n",
      "Generated 19088 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1266), 'Resting': np.int64(1461), 'Resting Ruminating': np.int64(784), 'Walking': np.int64(300)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1265), 'Resting': np.int64(1456), 'Resting Ruminating': np.int64(784), 'Walking': np.int64(299)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1264), 'Resting': np.int64(1449), 'Resting Ruminating': np.int64(785), 'Walking': np.int64(299)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1263), 'Resting': np.int64(1443), 'Resting Ruminating': np.int64(785), 'Walking': np.int64(299)}\n",
      "--- Resampling (10s) with Threshold 80.0% ---\n",
      "Generated 18680 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1239), 'Resting': np.int64(1435), 'Resting Ruminating': np.int64(781), 'Walking': np.int64(274)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1238), 'Resting': np.int64(1429), 'Resting Ruminating': np.int64(781), 'Walking': np.int64(274)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1237), 'Resting': np.int64(1423), 'Resting Ruminating': np.int64(781), 'Walking': np.int64(274)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(1236), 'Resting': np.int64(1417), 'Resting Ruminating': np.int64(781), 'Walking': np.int64(274)}\n",
      "--- Resampling (15s) with Threshold 60.0% ---\n",
      "Generated 12987 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(858), 'Resting': np.int64(1000), 'Resting Ruminating': np.int64(527), 'Walking': np.int64(206)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(857), 'Resting': np.int64(994), 'Resting Ruminating': np.int64(527), 'Walking': np.int64(206)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(856), 'Resting': np.int64(988), 'Resting Ruminating': np.int64(527), 'Walking': np.int64(206)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(855), 'Resting': np.int64(983), 'Resting Ruminating': np.int64(526), 'Walking': np.int64(206)}\n",
      "--- Resampling (15s) with Threshold 70.0% ---\n",
      "Generated 12491 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(829), 'Resting': np.int64(962), 'Resting Ruminating': np.int64(523), 'Walking': np.int64(178)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(828), 'Resting': np.int64(956), 'Resting Ruminating': np.int64(523), 'Walking': np.int64(178)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(827), 'Resting': np.int64(950), 'Resting Ruminating': np.int64(523), 'Walking': np.int64(178)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(826), 'Resting': np.int64(944), 'Resting Ruminating': np.int64(524), 'Walking': np.int64(177)}\n",
      "--- Resampling (15s) with Threshold 80.0% ---\n",
      "Generated 12015 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(800), 'Resting': np.int64(923), 'Resting Ruminating': np.int64(519), 'Walking': np.int64(154)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(799), 'Resting': np.int64(917), 'Resting Ruminating': np.int64(519), 'Walking': np.int64(154)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(798), 'Resting': np.int64(911), 'Resting Ruminating': np.int64(519), 'Walking': np.int64(154)}\n",
      "Early stopping at epoch 19\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(797), 'Resting': np.int64(906), 'Resting Ruminating': np.int64(519), 'Walking': np.int64(153)}\n",
      "--- Resampling (30s) with Threshold 60.0% ---\n",
      "Generated 6382 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(425), 'Resting': np.int64(494), 'Resting Ruminating': np.int64(265), 'Walking': np.int64(86)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(424), 'Resting': np.int64(488), 'Resting Ruminating': np.int64(265), 'Walking': np.int64(86)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(424), 'Resting': np.int64(483), 'Resting Ruminating': np.int64(265), 'Walking': np.int64(84)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(423), 'Resting': np.int64(479), 'Resting Ruminating': np.int64(266), 'Walking': np.int64(81)}\n",
      "--- Resampling (30s) with Threshold 70.0% ---\n",
      "Generated 6058 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(404), 'Resting': np.int64(468), 'Resting Ruminating': np.int64(263), 'Walking': np.int64(70)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(403), 'Resting': np.int64(463), 'Resting Ruminating': np.int64(263), 'Walking': np.int64(69)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(403), 'Resting': np.int64(458), 'Resting Ruminating': np.int64(263), 'Walking': np.int64(67)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(402), 'Resting': np.int64(454), 'Resting Ruminating': np.int64(263), 'Walking': np.int64(65)}\n",
      "--- Resampling (30s) with Threshold 80.0% ---\n",
      "Generated 5716 labeled windows.\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 5 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(380), 'Resting': np.int64(441), 'Resting Ruminating': np.int64(258), 'Walking': np.int64(58)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 10 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(379), 'Resting': np.int64(436), 'Resting Ruminating': np.int64(258), 'Walking': np.int64(57)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 15 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(378), 'Resting': np.int64(432), 'Resting Ruminating': np.int64(258), 'Walking': np.int64(55)}\n",
      "\n",
      ">>> Running PyTorch Time Series Model (Lookback: 20 steps)\n",
      "[INFO] Test Set Distribution: {'Grazing': np.int64(377), 'Resting': np.int64(427), 'Resting Ruminating': np.int64(258), 'Walking': np.int64(54)}\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "    Accuracy  F1_Score  Time_Steps  Num_Training_Sequences  Test_Samples  \\\n",
      "11  0.903389  0.899935          20                   30927          7732   \n",
      "35  0.903158  0.898334          20                    9500          2375   \n",
      "19  0.899472  0.895727          20                   15158          3790   \n",
      "7   0.900217  0.895672          20                   31305          7827   \n",
      "47  0.896953  0.893242          20                    4460          1116   \n",
      "22  0.897443  0.891712          15                   14860          3715   \n",
      "23  0.895901  0.890969          20                   14832          3708   \n",
      "10  0.894043  0.889001          15                   30955          7739   \n",
      "3   0.890782  0.883626          20                   31932          7984   \n",
      "18  0.886753  0.882746          15                   15186          3797   \n",
      "31  0.886281  0.881476          20                    9880          2471   \n",
      "34  0.884551  0.881449          15                    9528          2382   \n",
      "33  0.885726  0.881424          10                    9556          2389   \n",
      "46  0.884239  0.879979          15                    4488          1123   \n",
      "21  0.881515  0.876966          10                   14888          3722   \n",
      "2   0.883744  0.876591          15                   31960          7991   \n",
      "6   0.882563  0.875664          15                   31333          7834   \n",
      "9   0.882907  0.875515          10                   30983          7746   \n",
      "15  0.879112  0.873365          20                   15680          3921   \n",
      "39  0.875901  0.871365          20                    4993          1249   \n",
      "45  0.873451  0.870559          10                    4516          1130   \n",
      "5   0.876546  0.869759          10                   31361          7841   \n",
      "43  0.875845  0.869297          20                    4734          1184   \n",
      "17  0.874343  0.868275          10                   15214          3804   \n",
      "30  0.875706  0.867951          15                    9908          2478   \n",
      "14  0.869654  0.863060          15                   15708          3928   \n",
      "27  0.865370  0.862235          20                   10277          2570   \n",
      "32  0.864357  0.861698           5                    9584          2396   \n",
      "1   0.865341  0.858512          10                   31988          7998   \n",
      "26  0.866123  0.858115          15                   10305          2577   \n",
      "29  0.865594  0.857462          10                    9936          2485   \n",
      "13  0.859975  0.852772          10                   15736          3935   \n",
      "41  0.862270  0.850358          10                    4790          1198   \n",
      "38  0.856688  0.849240          15                    5021          1256   \n",
      "42  0.855584  0.849218          15                    4762          1191   \n",
      "44  0.852243  0.848289           5                    4544          1137   \n",
      "37  0.852732  0.846402          10                    5049          1263   \n",
      "20  0.851167  0.845400           5                   14916          3729   \n",
      "8   0.849607  0.841987           5                   31011          7753   \n",
      "25  0.848684  0.839920          10                   10333          2584   \n",
      "4   0.846840  0.839801           5                   31389          7848   \n",
      "16  0.846759  0.836367           5                   15242          3811   \n",
      "28  0.840690  0.834249           5                    9964          2492   \n",
      "0   0.835728  0.829197           5                   32016          8005   \n",
      "12  0.833841  0.824296           5                   15764          3942   \n",
      "24  0.826322  0.816546           5                   10361          2591   \n",
      "36  0.825984  0.816353           5                    5077          1270   \n",
      "40  0.826556  0.814405           5                    4818          1205   \n",
      "\n",
      "                                    Test_Label_Counts  Window_Size_Sec  \\\n",
      "11  {'Grazing': np.int64(2562), 'Resting': np.int6...                5   \n",
      "35  {'Grazing': np.int64(797), 'Resting': np.int64...               15   \n",
      "19  {'Grazing': np.int64(1263), 'Resting': np.int6...               10   \n",
      "7   {'Grazing': np.int64(2589), 'Resting': np.int6...                5   \n",
      "47  {'Grazing': np.int64(377), 'Resting': np.int64...               30   \n",
      "22  {'Grazing': np.int64(1237), 'Resting': np.int6...               10   \n",
      "23  {'Grazing': np.int64(1236), 'Resting': np.int6...               10   \n",
      "10  {'Grazing': np.int64(2563), 'Resting': np.int6...                5   \n",
      "3   {'Grazing': np.int64(2624), 'Resting': np.int6...                5   \n",
      "18  {'Grazing': np.int64(1264), 'Resting': np.int6...               10   \n",
      "31  {'Grazing': np.int64(826), 'Resting': np.int64...               15   \n",
      "34  {'Grazing': np.int64(798), 'Resting': np.int64...               15   \n",
      "33  {'Grazing': np.int64(799), 'Resting': np.int64...               15   \n",
      "46  {'Grazing': np.int64(378), 'Resting': np.int64...               30   \n",
      "21  {'Grazing': np.int64(1238), 'Resting': np.int6...               10   \n",
      "2   {'Grazing': np.int64(2626), 'Resting': np.int6...                5   \n",
      "6   {'Grazing': np.int64(2590), 'Resting': np.int6...                5   \n",
      "9   {'Grazing': np.int64(2565), 'Resting': np.int6...                5   \n",
      "15  {'Grazing': np.int64(1298), 'Resting': np.int6...               10   \n",
      "39  {'Grazing': np.int64(423), 'Resting': np.int64...               30   \n",
      "45  {'Grazing': np.int64(379), 'Resting': np.int64...               30   \n",
      "5   {'Grazing': np.int64(2592), 'Resting': np.int6...                5   \n",
      "43  {'Grazing': np.int64(402), 'Resting': np.int64...               30   \n",
      "17  {'Grazing': np.int64(1265), 'Resting': np.int6...               10   \n",
      "30  {'Grazing': np.int64(827), 'Resting': np.int64...               15   \n",
      "14  {'Grazing': np.int64(1298), 'Resting': np.int6...               10   \n",
      "27  {'Grazing': np.int64(855), 'Resting': np.int64...               15   \n",
      "32  {'Grazing': np.int64(800), 'Resting': np.int64...               15   \n",
      "1   {'Grazing': np.int64(2627), 'Resting': np.int6...                5   \n",
      "26  {'Grazing': np.int64(856), 'Resting': np.int64...               15   \n",
      "29  {'Grazing': np.int64(828), 'Resting': np.int64...               15   \n",
      "13  {'Grazing': np.int64(1299), 'Resting': np.int6...               10   \n",
      "41  {'Grazing': np.int64(403), 'Resting': np.int64...               30   \n",
      "38  {'Grazing': np.int64(424), 'Resting': np.int64...               30   \n",
      "42  {'Grazing': np.int64(403), 'Resting': np.int64...               30   \n",
      "44  {'Grazing': np.int64(380), 'Resting': np.int64...               30   \n",
      "37  {'Grazing': np.int64(424), 'Resting': np.int64...               30   \n",
      "20  {'Grazing': np.int64(1239), 'Resting': np.int6...               10   \n",
      "8   {'Grazing': np.int64(2566), 'Resting': np.int6...                5   \n",
      "25  {'Grazing': np.int64(857), 'Resting': np.int64...               15   \n",
      "4   {'Grazing': np.int64(2593), 'Resting': np.int6...                5   \n",
      "16  {'Grazing': np.int64(1266), 'Resting': np.int6...               10   \n",
      "28  {'Grazing': np.int64(829), 'Resting': np.int64...               15   \n",
      "0   {'Grazing': np.int64(2628), 'Resting': np.int6...                5   \n",
      "12  {'Grazing': np.int64(1301), 'Resting': np.int6...               10   \n",
      "24  {'Grazing': np.int64(858), 'Resting': np.int64...               15   \n",
      "36  {'Grazing': np.int64(425), 'Resting': np.int64...               30   \n",
      "40  {'Grazing': np.int64(404), 'Resting': np.int64...               30   \n",
      "\n",
      "    Label_Threshold  \n",
      "11              0.8  \n",
      "35              0.8  \n",
      "19              0.7  \n",
      "7               0.7  \n",
      "47              0.8  \n",
      "22              0.8  \n",
      "23              0.8  \n",
      "10              0.8  \n",
      "3               0.6  \n",
      "18              0.7  \n",
      "31              0.7  \n",
      "34              0.8  \n",
      "33              0.8  \n",
      "46              0.8  \n",
      "21              0.8  \n",
      "2               0.6  \n",
      "6               0.7  \n",
      "9               0.8  \n",
      "15              0.6  \n",
      "39              0.6  \n",
      "45              0.8  \n",
      "5               0.7  \n",
      "43              0.7  \n",
      "17              0.7  \n",
      "30              0.7  \n",
      "14              0.6  \n",
      "27              0.6  \n",
      "32              0.8  \n",
      "1               0.6  \n",
      "26              0.6  \n",
      "29              0.7  \n",
      "13              0.6  \n",
      "41              0.7  \n",
      "38              0.6  \n",
      "42              0.7  \n",
      "44              0.8  \n",
      "37              0.6  \n",
      "20              0.8  \n",
      "8               0.8  \n",
      "25              0.6  \n",
      "4               0.7  \n",
      "16              0.7  \n",
      "28              0.7  \n",
      "0               0.6  \n",
      "12              0.6  \n",
      "24              0.6  \n",
      "36              0.6  \n",
      "40              0.7  \n"
     ]
    }
   ],
   "source": [
    "results_table = []\n",
    "\n",
    "# Grid Search\n",
    "intervals = [5,10,15, 30] \n",
    "thresholds = [0.6,0.7, 0.8] \n",
    "lstm_steps = [5,10,15,20]     \n",
    "\n",
    "print(f\"\\n--- Starting Grid Search (PyTorch) ---\")\n",
    "for iv in intervals:\n",
    "    for th in thresholds:\n",
    "        df_ready = pipeline.resample_and_label(interval_seconds=iv, coherence_threshold=th)\n",
    "        \n",
    "        if len(df_ready) < 100:\n",
    "            print(f\"Skipping Interval={iv}, Threshold={th} (Not enough valid windows)\")\n",
    "            continue\n",
    "\n",
    "        # 4. Run PyTorch Time Series Model\n",
    "        ts_modeler = PytorchTimeSeriesModeler(pipeline, df_ready)\n",
    "        \n",
    "        for steps in lstm_steps:\n",
    "            res = ts_modeler.run(time_steps=steps, epochs=20, batch_size=32)\n",
    "            if res:\n",
    "                res['Window_Size_Sec'] = iv\n",
    "                res['Label_Threshold'] = th\n",
    "                results_table.append(res)\n",
    "\n",
    "# C. SAVE RESULTS\n",
    "if results_table:\n",
    "    final_df = pd.DataFrame(results_table)\n",
    "    final_df = final_df.sort_values(by='F1_Score', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    print(final_df)\n",
    "    \n",
    "    save_path = '/home/rajesh/work/acclerometer_project/codes/pytorch_results.csv'\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    final_df.to_csv(save_path, index=False)\n",
    "else:\n",
    "    print(\"No results generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5434ca07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Time_Steps</th>\n",
       "      <th>Num_Training_Sequences</th>\n",
       "      <th>Test_Samples</th>\n",
       "      <th>Test_Label_Counts</th>\n",
       "      <th>Window_Size_Sec</th>\n",
       "      <th>Label_Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.903389</td>\n",
       "      <td>0.899935</td>\n",
       "      <td>20</td>\n",
       "      <td>30927</td>\n",
       "      <td>7732</td>\n",
       "      <td>{'Grazing': np.int64(2562), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.903158</td>\n",
       "      <td>0.898334</td>\n",
       "      <td>20</td>\n",
       "      <td>9500</td>\n",
       "      <td>2375</td>\n",
       "      <td>{'Grazing': np.int64(797), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.899472</td>\n",
       "      <td>0.895727</td>\n",
       "      <td>20</td>\n",
       "      <td>15158</td>\n",
       "      <td>3790</td>\n",
       "      <td>{'Grazing': np.int64(1263), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.900217</td>\n",
       "      <td>0.895672</td>\n",
       "      <td>20</td>\n",
       "      <td>31305</td>\n",
       "      <td>7827</td>\n",
       "      <td>{'Grazing': np.int64(2589), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.896953</td>\n",
       "      <td>0.893242</td>\n",
       "      <td>20</td>\n",
       "      <td>4460</td>\n",
       "      <td>1116</td>\n",
       "      <td>{'Grazing': np.int64(377), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.897443</td>\n",
       "      <td>0.891712</td>\n",
       "      <td>15</td>\n",
       "      <td>14860</td>\n",
       "      <td>3715</td>\n",
       "      <td>{'Grazing': np.int64(1237), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.895901</td>\n",
       "      <td>0.890969</td>\n",
       "      <td>20</td>\n",
       "      <td>14832</td>\n",
       "      <td>3708</td>\n",
       "      <td>{'Grazing': np.int64(1236), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.894043</td>\n",
       "      <td>0.889001</td>\n",
       "      <td>15</td>\n",
       "      <td>30955</td>\n",
       "      <td>7739</td>\n",
       "      <td>{'Grazing': np.int64(2563), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.890782</td>\n",
       "      <td>0.883626</td>\n",
       "      <td>20</td>\n",
       "      <td>31932</td>\n",
       "      <td>7984</td>\n",
       "      <td>{'Grazing': np.int64(2624), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.886753</td>\n",
       "      <td>0.882746</td>\n",
       "      <td>15</td>\n",
       "      <td>15186</td>\n",
       "      <td>3797</td>\n",
       "      <td>{'Grazing': np.int64(1264), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.886281</td>\n",
       "      <td>0.881476</td>\n",
       "      <td>20</td>\n",
       "      <td>9880</td>\n",
       "      <td>2471</td>\n",
       "      <td>{'Grazing': np.int64(826), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.884551</td>\n",
       "      <td>0.881449</td>\n",
       "      <td>15</td>\n",
       "      <td>9528</td>\n",
       "      <td>2382</td>\n",
       "      <td>{'Grazing': np.int64(798), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.885726</td>\n",
       "      <td>0.881424</td>\n",
       "      <td>10</td>\n",
       "      <td>9556</td>\n",
       "      <td>2389</td>\n",
       "      <td>{'Grazing': np.int64(799), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.884239</td>\n",
       "      <td>0.879979</td>\n",
       "      <td>15</td>\n",
       "      <td>4488</td>\n",
       "      <td>1123</td>\n",
       "      <td>{'Grazing': np.int64(378), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.881515</td>\n",
       "      <td>0.876966</td>\n",
       "      <td>10</td>\n",
       "      <td>14888</td>\n",
       "      <td>3722</td>\n",
       "      <td>{'Grazing': np.int64(1238), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.883744</td>\n",
       "      <td>0.876591</td>\n",
       "      <td>15</td>\n",
       "      <td>31960</td>\n",
       "      <td>7991</td>\n",
       "      <td>{'Grazing': np.int64(2626), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.882563</td>\n",
       "      <td>0.875664</td>\n",
       "      <td>15</td>\n",
       "      <td>31333</td>\n",
       "      <td>7834</td>\n",
       "      <td>{'Grazing': np.int64(2590), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.882907</td>\n",
       "      <td>0.875515</td>\n",
       "      <td>10</td>\n",
       "      <td>30983</td>\n",
       "      <td>7746</td>\n",
       "      <td>{'Grazing': np.int64(2565), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.879112</td>\n",
       "      <td>0.873365</td>\n",
       "      <td>20</td>\n",
       "      <td>15680</td>\n",
       "      <td>3921</td>\n",
       "      <td>{'Grazing': np.int64(1298), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.875901</td>\n",
       "      <td>0.871365</td>\n",
       "      <td>20</td>\n",
       "      <td>4993</td>\n",
       "      <td>1249</td>\n",
       "      <td>{'Grazing': np.int64(423), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.873451</td>\n",
       "      <td>0.870559</td>\n",
       "      <td>10</td>\n",
       "      <td>4516</td>\n",
       "      <td>1130</td>\n",
       "      <td>{'Grazing': np.int64(379), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.876546</td>\n",
       "      <td>0.869759</td>\n",
       "      <td>10</td>\n",
       "      <td>31361</td>\n",
       "      <td>7841</td>\n",
       "      <td>{'Grazing': np.int64(2592), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.875845</td>\n",
       "      <td>0.869297</td>\n",
       "      <td>20</td>\n",
       "      <td>4734</td>\n",
       "      <td>1184</td>\n",
       "      <td>{'Grazing': np.int64(402), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.874343</td>\n",
       "      <td>0.868275</td>\n",
       "      <td>10</td>\n",
       "      <td>15214</td>\n",
       "      <td>3804</td>\n",
       "      <td>{'Grazing': np.int64(1265), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.875706</td>\n",
       "      <td>0.867951</td>\n",
       "      <td>15</td>\n",
       "      <td>9908</td>\n",
       "      <td>2478</td>\n",
       "      <td>{'Grazing': np.int64(827), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.869654</td>\n",
       "      <td>0.863060</td>\n",
       "      <td>15</td>\n",
       "      <td>15708</td>\n",
       "      <td>3928</td>\n",
       "      <td>{'Grazing': np.int64(1298), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.865370</td>\n",
       "      <td>0.862235</td>\n",
       "      <td>20</td>\n",
       "      <td>10277</td>\n",
       "      <td>2570</td>\n",
       "      <td>{'Grazing': np.int64(855), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.864357</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>5</td>\n",
       "      <td>9584</td>\n",
       "      <td>2396</td>\n",
       "      <td>{'Grazing': np.int64(800), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.865341</td>\n",
       "      <td>0.858512</td>\n",
       "      <td>10</td>\n",
       "      <td>31988</td>\n",
       "      <td>7998</td>\n",
       "      <td>{'Grazing': np.int64(2627), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.866123</td>\n",
       "      <td>0.858115</td>\n",
       "      <td>15</td>\n",
       "      <td>10305</td>\n",
       "      <td>2577</td>\n",
       "      <td>{'Grazing': np.int64(856), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.865594</td>\n",
       "      <td>0.857462</td>\n",
       "      <td>10</td>\n",
       "      <td>9936</td>\n",
       "      <td>2485</td>\n",
       "      <td>{'Grazing': np.int64(828), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.859975</td>\n",
       "      <td>0.852772</td>\n",
       "      <td>10</td>\n",
       "      <td>15736</td>\n",
       "      <td>3935</td>\n",
       "      <td>{'Grazing': np.int64(1299), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.862270</td>\n",
       "      <td>0.850358</td>\n",
       "      <td>10</td>\n",
       "      <td>4790</td>\n",
       "      <td>1198</td>\n",
       "      <td>{'Grazing': np.int64(403), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.856688</td>\n",
       "      <td>0.849240</td>\n",
       "      <td>15</td>\n",
       "      <td>5021</td>\n",
       "      <td>1256</td>\n",
       "      <td>{'Grazing': np.int64(424), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.855584</td>\n",
       "      <td>0.849218</td>\n",
       "      <td>15</td>\n",
       "      <td>4762</td>\n",
       "      <td>1191</td>\n",
       "      <td>{'Grazing': np.int64(403), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.852243</td>\n",
       "      <td>0.848289</td>\n",
       "      <td>5</td>\n",
       "      <td>4544</td>\n",
       "      <td>1137</td>\n",
       "      <td>{'Grazing': np.int64(380), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.852732</td>\n",
       "      <td>0.846402</td>\n",
       "      <td>10</td>\n",
       "      <td>5049</td>\n",
       "      <td>1263</td>\n",
       "      <td>{'Grazing': np.int64(424), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.851167</td>\n",
       "      <td>0.845400</td>\n",
       "      <td>5</td>\n",
       "      <td>14916</td>\n",
       "      <td>3729</td>\n",
       "      <td>{'Grazing': np.int64(1239), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.849607</td>\n",
       "      <td>0.841987</td>\n",
       "      <td>5</td>\n",
       "      <td>31011</td>\n",
       "      <td>7753</td>\n",
       "      <td>{'Grazing': np.int64(2566), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.839920</td>\n",
       "      <td>10</td>\n",
       "      <td>10333</td>\n",
       "      <td>2584</td>\n",
       "      <td>{'Grazing': np.int64(857), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.846840</td>\n",
       "      <td>0.839801</td>\n",
       "      <td>5</td>\n",
       "      <td>31389</td>\n",
       "      <td>7848</td>\n",
       "      <td>{'Grazing': np.int64(2593), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.846759</td>\n",
       "      <td>0.836367</td>\n",
       "      <td>5</td>\n",
       "      <td>15242</td>\n",
       "      <td>3811</td>\n",
       "      <td>{'Grazing': np.int64(1266), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.840690</td>\n",
       "      <td>0.834249</td>\n",
       "      <td>5</td>\n",
       "      <td>9964</td>\n",
       "      <td>2492</td>\n",
       "      <td>{'Grazing': np.int64(829), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.835728</td>\n",
       "      <td>0.829197</td>\n",
       "      <td>5</td>\n",
       "      <td>32016</td>\n",
       "      <td>8005</td>\n",
       "      <td>{'Grazing': np.int64(2628), 'Resting': np.int6...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.833841</td>\n",
       "      <td>0.824296</td>\n",
       "      <td>5</td>\n",
       "      <td>15764</td>\n",
       "      <td>3942</td>\n",
       "      <td>{'Grazing': np.int64(1301), 'Resting': np.int6...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.826322</td>\n",
       "      <td>0.816546</td>\n",
       "      <td>5</td>\n",
       "      <td>10361</td>\n",
       "      <td>2591</td>\n",
       "      <td>{'Grazing': np.int64(858), 'Resting': np.int64...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.825984</td>\n",
       "      <td>0.816353</td>\n",
       "      <td>5</td>\n",
       "      <td>5077</td>\n",
       "      <td>1270</td>\n",
       "      <td>{'Grazing': np.int64(425), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.826556</td>\n",
       "      <td>0.814405</td>\n",
       "      <td>5</td>\n",
       "      <td>4818</td>\n",
       "      <td>1205</td>\n",
       "      <td>{'Grazing': np.int64(404), 'Resting': np.int64...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F1_Score  Time_Steps  Num_Training_Sequences  Test_Samples  \\\n",
       "11  0.903389  0.899935          20                   30927          7732   \n",
       "35  0.903158  0.898334          20                    9500          2375   \n",
       "19  0.899472  0.895727          20                   15158          3790   \n",
       "7   0.900217  0.895672          20                   31305          7827   \n",
       "47  0.896953  0.893242          20                    4460          1116   \n",
       "22  0.897443  0.891712          15                   14860          3715   \n",
       "23  0.895901  0.890969          20                   14832          3708   \n",
       "10  0.894043  0.889001          15                   30955          7739   \n",
       "3   0.890782  0.883626          20                   31932          7984   \n",
       "18  0.886753  0.882746          15                   15186          3797   \n",
       "31  0.886281  0.881476          20                    9880          2471   \n",
       "34  0.884551  0.881449          15                    9528          2382   \n",
       "33  0.885726  0.881424          10                    9556          2389   \n",
       "46  0.884239  0.879979          15                    4488          1123   \n",
       "21  0.881515  0.876966          10                   14888          3722   \n",
       "2   0.883744  0.876591          15                   31960          7991   \n",
       "6   0.882563  0.875664          15                   31333          7834   \n",
       "9   0.882907  0.875515          10                   30983          7746   \n",
       "15  0.879112  0.873365          20                   15680          3921   \n",
       "39  0.875901  0.871365          20                    4993          1249   \n",
       "45  0.873451  0.870559          10                    4516          1130   \n",
       "5   0.876546  0.869759          10                   31361          7841   \n",
       "43  0.875845  0.869297          20                    4734          1184   \n",
       "17  0.874343  0.868275          10                   15214          3804   \n",
       "30  0.875706  0.867951          15                    9908          2478   \n",
       "14  0.869654  0.863060          15                   15708          3928   \n",
       "27  0.865370  0.862235          20                   10277          2570   \n",
       "32  0.864357  0.861698           5                    9584          2396   \n",
       "1   0.865341  0.858512          10                   31988          7998   \n",
       "26  0.866123  0.858115          15                   10305          2577   \n",
       "29  0.865594  0.857462          10                    9936          2485   \n",
       "13  0.859975  0.852772          10                   15736          3935   \n",
       "41  0.862270  0.850358          10                    4790          1198   \n",
       "38  0.856688  0.849240          15                    5021          1256   \n",
       "42  0.855584  0.849218          15                    4762          1191   \n",
       "44  0.852243  0.848289           5                    4544          1137   \n",
       "37  0.852732  0.846402          10                    5049          1263   \n",
       "20  0.851167  0.845400           5                   14916          3729   \n",
       "8   0.849607  0.841987           5                   31011          7753   \n",
       "25  0.848684  0.839920          10                   10333          2584   \n",
       "4   0.846840  0.839801           5                   31389          7848   \n",
       "16  0.846759  0.836367           5                   15242          3811   \n",
       "28  0.840690  0.834249           5                    9964          2492   \n",
       "0   0.835728  0.829197           5                   32016          8005   \n",
       "12  0.833841  0.824296           5                   15764          3942   \n",
       "24  0.826322  0.816546           5                   10361          2591   \n",
       "36  0.825984  0.816353           5                    5077          1270   \n",
       "40  0.826556  0.814405           5                    4818          1205   \n",
       "\n",
       "                                    Test_Label_Counts  Window_Size_Sec  \\\n",
       "11  {'Grazing': np.int64(2562), 'Resting': np.int6...                5   \n",
       "35  {'Grazing': np.int64(797), 'Resting': np.int64...               15   \n",
       "19  {'Grazing': np.int64(1263), 'Resting': np.int6...               10   \n",
       "7   {'Grazing': np.int64(2589), 'Resting': np.int6...                5   \n",
       "47  {'Grazing': np.int64(377), 'Resting': np.int64...               30   \n",
       "22  {'Grazing': np.int64(1237), 'Resting': np.int6...               10   \n",
       "23  {'Grazing': np.int64(1236), 'Resting': np.int6...               10   \n",
       "10  {'Grazing': np.int64(2563), 'Resting': np.int6...                5   \n",
       "3   {'Grazing': np.int64(2624), 'Resting': np.int6...                5   \n",
       "18  {'Grazing': np.int64(1264), 'Resting': np.int6...               10   \n",
       "31  {'Grazing': np.int64(826), 'Resting': np.int64...               15   \n",
       "34  {'Grazing': np.int64(798), 'Resting': np.int64...               15   \n",
       "33  {'Grazing': np.int64(799), 'Resting': np.int64...               15   \n",
       "46  {'Grazing': np.int64(378), 'Resting': np.int64...               30   \n",
       "21  {'Grazing': np.int64(1238), 'Resting': np.int6...               10   \n",
       "2   {'Grazing': np.int64(2626), 'Resting': np.int6...                5   \n",
       "6   {'Grazing': np.int64(2590), 'Resting': np.int6...                5   \n",
       "9   {'Grazing': np.int64(2565), 'Resting': np.int6...                5   \n",
       "15  {'Grazing': np.int64(1298), 'Resting': np.int6...               10   \n",
       "39  {'Grazing': np.int64(423), 'Resting': np.int64...               30   \n",
       "45  {'Grazing': np.int64(379), 'Resting': np.int64...               30   \n",
       "5   {'Grazing': np.int64(2592), 'Resting': np.int6...                5   \n",
       "43  {'Grazing': np.int64(402), 'Resting': np.int64...               30   \n",
       "17  {'Grazing': np.int64(1265), 'Resting': np.int6...               10   \n",
       "30  {'Grazing': np.int64(827), 'Resting': np.int64...               15   \n",
       "14  {'Grazing': np.int64(1298), 'Resting': np.int6...               10   \n",
       "27  {'Grazing': np.int64(855), 'Resting': np.int64...               15   \n",
       "32  {'Grazing': np.int64(800), 'Resting': np.int64...               15   \n",
       "1   {'Grazing': np.int64(2627), 'Resting': np.int6...                5   \n",
       "26  {'Grazing': np.int64(856), 'Resting': np.int64...               15   \n",
       "29  {'Grazing': np.int64(828), 'Resting': np.int64...               15   \n",
       "13  {'Grazing': np.int64(1299), 'Resting': np.int6...               10   \n",
       "41  {'Grazing': np.int64(403), 'Resting': np.int64...               30   \n",
       "38  {'Grazing': np.int64(424), 'Resting': np.int64...               30   \n",
       "42  {'Grazing': np.int64(403), 'Resting': np.int64...               30   \n",
       "44  {'Grazing': np.int64(380), 'Resting': np.int64...               30   \n",
       "37  {'Grazing': np.int64(424), 'Resting': np.int64...               30   \n",
       "20  {'Grazing': np.int64(1239), 'Resting': np.int6...               10   \n",
       "8   {'Grazing': np.int64(2566), 'Resting': np.int6...                5   \n",
       "25  {'Grazing': np.int64(857), 'Resting': np.int64...               15   \n",
       "4   {'Grazing': np.int64(2593), 'Resting': np.int6...                5   \n",
       "16  {'Grazing': np.int64(1266), 'Resting': np.int6...               10   \n",
       "28  {'Grazing': np.int64(829), 'Resting': np.int64...               15   \n",
       "0   {'Grazing': np.int64(2628), 'Resting': np.int6...                5   \n",
       "12  {'Grazing': np.int64(1301), 'Resting': np.int6...               10   \n",
       "24  {'Grazing': np.int64(858), 'Resting': np.int64...               15   \n",
       "36  {'Grazing': np.int64(425), 'Resting': np.int64...               30   \n",
       "40  {'Grazing': np.int64(404), 'Resting': np.int64...               30   \n",
       "\n",
       "    Label_Threshold  \n",
       "11              0.8  \n",
       "35              0.8  \n",
       "19              0.7  \n",
       "7               0.7  \n",
       "47              0.8  \n",
       "22              0.8  \n",
       "23              0.8  \n",
       "10              0.8  \n",
       "3               0.6  \n",
       "18              0.7  \n",
       "31              0.7  \n",
       "34              0.8  \n",
       "33              0.8  \n",
       "46              0.8  \n",
       "21              0.8  \n",
       "2               0.6  \n",
       "6               0.7  \n",
       "9               0.8  \n",
       "15              0.6  \n",
       "39              0.6  \n",
       "45              0.8  \n",
       "5               0.7  \n",
       "43              0.7  \n",
       "17              0.7  \n",
       "30              0.7  \n",
       "14              0.6  \n",
       "27              0.6  \n",
       "32              0.8  \n",
       "1               0.6  \n",
       "26              0.6  \n",
       "29              0.7  \n",
       "13              0.6  \n",
       "41              0.7  \n",
       "38              0.6  \n",
       "42              0.7  \n",
       "44              0.8  \n",
       "37              0.6  \n",
       "20              0.8  \n",
       "8               0.8  \n",
       "25              0.6  \n",
       "4               0.7  \n",
       "16              0.7  \n",
       "28              0.7  \n",
       "0               0.6  \n",
       "12              0.6  \n",
       "24              0.6  \n",
       "36              0.6  \n",
       "40              0.7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d2a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_stat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
